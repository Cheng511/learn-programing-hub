[ä¸Šä¸€ç« ï¼šè‡ªç„¶èªè¨€è™•ç†åŸºç¤](100_è‡ªç„¶èªè¨€è™•ç†åŸºç¤.md) | [ä¸‹ä¸€ç« ï¼šè¨ˆç®—æ©Ÿè¦–è¦ºåŸºç¤](102_è¨ˆç®—æ©Ÿè¦–è¦ºåŸºç¤.md)

# Python è‡ªç„¶èªè¨€è™•ç†é€²éš ğŸ“

## é«˜ç´šæ–‡æœ¬è™•ç†

### 1. æ–‡æœ¬åˆ†é¡

```python
import numpy as np
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.linear_model import LogisticRegression
from sklearn.svm import LinearSVC
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from typing import List, Dict, Set, Tuple
import time
import sys
import os

class TextClassifier:
    def __init__(self):
        """åˆå§‹åŒ–æ–‡æœ¬åˆ†é¡å™¨"""
        try:
            # åˆå§‹åŒ–ç‰¹å¾µæå–å™¨
            self.vectorizer = TfidfVectorizer()
            
            # åˆå§‹åŒ–åˆ†é¡å™¨
            self.nb_classifier = MultinomialNB()
            self.lr_classifier = LogisticRegression()
            self.svm_classifier = LinearSVC()
            
            # é¸æ“‡æœ€ä½³åˆ†é¡å™¨
            self.best_classifier = None
            self.best_score = 0
            
            print("Text classifier initialized")
            
        except Exception as e:
            print(f"Error initializing text classifier: {e}")
    
    def extract_features(self, texts: List[str]) -> np.ndarray:
        """æå–ç‰¹å¾µ"""
        try:
            # æ“¬åˆä¸¦è½‰æ›æ–‡æœ¬
            features = self.vectorizer.fit_transform(texts)
            return features
            
        except Exception as e:
            print(f"Error extracting features: {e}")
            return np.array([])
    
    def train_naive_bayes(self, X_train: np.ndarray, y_train: np.ndarray):
        """è¨“ç·´æ¨¸ç´ è²è‘‰æ–¯åˆ†é¡å™¨"""
        try:
            # è¨“ç·´æ¨¡å‹
            self.nb_classifier.fit(X_train, y_train)
            print("Naive Bayes classifier trained")
            
        except Exception as e:
            print(f"Error training Naive Bayes classifier: {e}")
    
    def train_logistic_regression(self, X_train: np.ndarray, y_train: np.ndarray):
        """è¨“ç·´é‚è¼¯å›æ­¸åˆ†é¡å™¨"""
        try:
            # è¨“ç·´æ¨¡å‹
            self.lr_classifier.fit(X_train, y_train)
            print("Logistic Regression classifier trained")
            
        except Exception as e:
            print(f"Error training Logistic Regression classifier: {e}")
    
    def train_svm(self, X_train: np.ndarray, y_train: np.ndarray):
        """è¨“ç·´SVMåˆ†é¡å™¨"""
        try:
            # è¨“ç·´æ¨¡å‹
            self.svm_classifier.fit(X_train, y_train)
            print("SVM classifier trained")
            
        except Exception as e:
            print(f"Error training SVM classifier: {e}")
    
    def evaluate_classifier(self, classifier, X_test: np.ndarray, y_test: np.ndarray) -> Tuple[float, str, np.ndarray]:
        """è©•ä¼°åˆ†é¡å™¨"""
        try:
            # é æ¸¬
            y_pred = classifier.predict(X_test)
            
            # è¨ˆç®—æº–ç¢ºç‡
            accuracy = accuracy_score(y_test, y_pred)
            
            # ç”Ÿæˆåˆ†é¡å ±å‘Š
            report = classification_report(y_test, y_pred)
            
            # ç”Ÿæˆæ··æ·†çŸ©é™£
            cm = confusion_matrix(y_test, y_pred)
            
            return accuracy, report, cm
            
        except Exception as e:
            print(f"Error evaluating classifier: {e}")
            return 0.0, "", np.array([])
    
    def select_best_classifier(self, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray):
        """é¸æ“‡æœ€ä½³åˆ†é¡å™¨"""
        try:
            # è¨“ç·´æ‰€æœ‰åˆ†é¡å™¨
            self.train_naive_bayes(X_train, y_train)
            self.train_logistic_regression(X_train, y_train)
            self.train_svm(X_train, y_train)
            
            # è©•ä¼°æ‰€æœ‰åˆ†é¡å™¨
            classifiers = {
                'Naive Bayes': self.nb_classifier,
                'Logistic Regression': self.lr_classifier,
                'SVM': self.svm_classifier
            }
            
            for name, classifier in classifiers.items():
                accuracy, _, _ = self.evaluate_classifier(classifier, X_val, y_val)
                print(f"{name} accuracy: {accuracy:.4f}")
                
                if accuracy > self.best_score:
                    self.best_score = accuracy
                    self.best_classifier = classifier
            
            print(f"Best classifier selected with accuracy: {self.best_score:.4f}")
            
        except Exception as e:
            print(f"Error selecting best classifier: {e}")
    
    def train(self, texts: List[str], labels: List[int], val_size: float = 0.2):
        """è¨“ç·´æ¨¡å‹"""
        try:
            # æå–ç‰¹å¾µ
            features = self.extract_features(texts)
            
            # åˆ†å‰²æ•¸æ“š
            n_samples = len(texts)
            n_val = int(n_samples * val_size)
            
            X_train = features[:-n_val]
            y_train = np.array(labels[:-n_val])
            X_val = features[-n_val:]
            y_val = np.array(labels[-n_val:])
            
            # é¸æ“‡æœ€ä½³åˆ†é¡å™¨
            self.select_best_classifier(X_train, y_train, X_val, y_val)
            
        except Exception as e:
            print(f"Error in training: {e}")
    
    def predict(self, texts: List[str]) -> np.ndarray:
        """é æ¸¬"""
        try:
            if self.best_classifier is None:
                raise ValueError("No classifier trained")
            
            # æå–ç‰¹å¾µ
            features = self.vectorizer.transform(texts)
            
            # é æ¸¬
            predictions = self.best_classifier.predict(features)
            return predictions
            
        except Exception as e:
            print(f"Error in prediction: {e}")
            return np.array([])

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # å‰µå»ºç¤ºä¾‹æ•¸æ“š
    texts = [
        "Natural Language Processing is a field of artificial intelligence.",
        "Machine Learning is a subset of artificial intelligence.",
        "Deep Learning is a subset of machine learning.",
        "Computer Vision is another field of artificial intelligence.",
        "Robotics combines hardware and software engineering."
    ]
    labels = [0, 0, 0, 1, 1]  # 0: NLP/ML, 1: CV/Robotics
    
    try:
        # å‰µå»ºæ–‡æœ¬åˆ†é¡å™¨
        classifier = TextClassifier()
        
        # è¨“ç·´æ¨¡å‹
        classifier.train(texts, labels)
        
        # é æ¸¬
        test_texts = ["Neural networks are used in deep learning.", "Robots use sensors for perception."]
        predictions = classifier.predict(test_texts)
        print(f"Predictions: {predictions}")
    
    except Exception as e:
        print(f"Error in main: {e}")

if __name__ == '__main__':
    main()
```

### 2. æ–‡æœ¬ç”Ÿæˆ

```python
import numpy as np
from typing import List, Dict, Set, Tuple
import time
import sys
import os

class TextGenerator:
    def __init__(self, n_gram: int = 2):
        """åˆå§‹åŒ–æ–‡æœ¬ç”Ÿæˆå™¨"""
        try:
            self.n_gram = n_gram
            self.ngram_dict = {}
            self.start_tokens = []
            
            print("Text generator initialized")
            
        except Exception as e:
            print(f"Error initializing text generator: {e}")
    
    def create_ngrams(self, tokens: List[str]) -> List[Tuple[str, ...]]:
        """å‰µå»ºN-gram"""
        try:
            ngrams = []
            for i in range(len(tokens) - self.n_gram + 1):
                ngram = tuple(tokens[i:i + self.n_gram])
                ngrams.append(ngram)
            return ngrams
            
        except Exception as e:
            print(f"Error creating N-grams: {e}")
            return []
    
    def build_ngram_dict(self, texts: List[str]):
        """æ§‹å»ºN-gramå­—å…¸"""
        try:
            for text in texts:
                # åˆ†è©
                tokens = text.split()
                
                # è¨˜éŒ„èµ·å§‹token
                if len(tokens) >= self.n_gram:
                    self.start_tokens.append(tuple(tokens[:self.n_gram - 1]))
                
                # å‰µå»ºN-gram
                ngrams = self.create_ngrams(tokens)
                
                # æ›´æ–°å­—å…¸
                for i in range(len(ngrams) - 1):
                    current = ngrams[i]
                    next_token = ngrams[i + 1][-1]
                    
                    if current not in self.ngram_dict:
                        self.ngram_dict[current] = []
                    self.ngram_dict[current].append(next_token)
            
            print("N-gram dictionary built")
            
        except Exception as e:
            print(f"Error building N-gram dictionary: {e}")
    
    def generate_text(self, max_length: int = 50) -> str:
        """ç”Ÿæˆæ–‡æœ¬"""
        try:
            if not self.ngram_dict:
                raise ValueError("No N-gram dictionary built")
            
            # é¸æ“‡èµ·å§‹token
            start_token = np.random.choice(self.start_tokens)
            generated_tokens = list(start_token)
            
            # ç”Ÿæˆæ–‡æœ¬
            while len(generated_tokens) < max_length:
                current = tuple(generated_tokens[-(self.n_gram - 1):])
                
                if current not in self.ngram_dict:
                    break
                
                # é¸æ“‡ä¸‹ä¸€å€‹token
                next_token = np.random.choice(self.ngram_dict[current])
                generated_tokens.append(next_token)
            
            return ' '.join(generated_tokens)
            
        except Exception as e:
            print(f"Error generating text: {e}")
            return ""
    
    def train(self, texts: List[str]):
        """è¨“ç·´æ¨¡å‹"""
        try:
            # æ§‹å»ºN-gramå­—å…¸
            self.build_ngram_dict(texts)
            
        except Exception as e:
            print(f"Error in training: {e}")
    
    def generate_multiple(self, num_texts: int = 5, max_length: int = 50) -> List[str]:
        """ç”Ÿæˆå¤šå€‹æ–‡æœ¬"""
        try:
            generated_texts = []
            for _ in range(num_texts):
                text = self.generate_text(max_length)
                if text:
                    generated_texts.append(text)
            return generated_texts
            
        except Exception as e:
            print(f"Error generating multiple texts: {e}")
            return []

# ä½¿ç”¨ç¤ºä¾‹
def main():
    # å‰µå»ºç¤ºä¾‹æ•¸æ“š
    texts = [
        "Natural Language Processing is a field of artificial intelligence.",
        "Machine Learning is a subset of artificial intelligence.",
        "Deep Learning is a subset of machine learning.",
        "Computer Vision is another field of artificial intelligence.",
        "Robotics combines hardware and software engineering."
    ]
    
    try:
        # å‰µå»ºæ–‡æœ¬ç”Ÿæˆå™¨
        generator = TextGenerator(n_gram=2)
        
        # è¨“ç·´æ¨¡å‹
        generator.train(texts)
        
        # ç”Ÿæˆæ–‡æœ¬
        generated_texts = generator.generate_multiple(num_texts=3)
        for i, text in enumerate(generated_texts, 1):
            print(f"Generated text {i}: {text}")
    
    except Exception as e:
        print(f"Error in main: {e}")

if __name__ == '__main__':
    main()
```

## ç·´ç¿’é¡Œ

1. **æ–‡æœ¬åˆ†é¡**
   é–‹ç™¼æ–‡æœ¬åˆ†é¡ï¼š
   - ç‰¹å¾µæå–
   - æ¨¡å‹è¨“ç·´
   - æ¨¡å‹è©•ä¼°
   - å„ªåŒ–æ€§èƒ½

2. **æ–‡æœ¬ç”Ÿæˆ**
   å‰µå»ºæ–‡æœ¬ç”Ÿæˆï¼š
   - N-gramæ¨¡å‹
   - æ–‡æœ¬ç”Ÿæˆ
   - å„ªåŒ–æ€§èƒ½
   - è™•ç†ç•°å¸¸

3. **è‡ªç„¶èªè¨€è™•ç†**
   å¯¦ç¾è‡ªç„¶èªè¨€è™•ç†ï¼š
   - è™•ç†æ–‡æœ¬
   - è¨“ç·´æ¨¡å‹
   - å„ªåŒ–æ€§èƒ½
   - è™•ç†ç•°å¸¸

## å°æé†’ ğŸ’¡

1. æ–‡æœ¬åˆ†é¡
   - é¸æ“‡åˆé©æ–¹æ³•
   - å„ªåŒ–åƒæ•¸
   - è™•ç†ç•°å¸¸
   - æä¾›ç›£æ§

2. æ–‡æœ¬ç”Ÿæˆ
   - é¸æ“‡åˆé©æ–¹æ³•
   - å„ªåŒ–æ€§èƒ½
   - è™•ç†ç•°å¸¸
   - æä¾›çµæœ

3. è‡ªç„¶èªè¨€è™•ç†
   - é¸æ“‡åˆé©ç®—æ³•
   - å„ªåŒ–æ€§èƒ½
   - è™•ç†ç•°å¸¸
   - æä¾›ç›£æ§

4. èª¿è©¦æŠ€å·§
   - ä½¿ç”¨é–‹ç™¼å·¥å…·
   - åˆ†ææ€§èƒ½
   - å„ªåŒ–é—œéµè·¯å¾‘
   - ç›£æ§è™•ç†ç‹€æ…‹

[ä¸Šä¸€ç« ï¼šè‡ªç„¶èªè¨€è™•ç†åŸºç¤](100_è‡ªç„¶èªè¨€è™•ç†åŸºç¤.md) | [ä¸‹ä¸€ç« ï¼šè¨ˆç®—æ©Ÿè¦–è¦ºåŸºç¤](102_è¨ˆç®—æ©Ÿè¦–è¦ºåŸºç¤.md) 