[ä¸Šä¸€ç« ï¼šé€²éšè³‡æ–™åº«æ“ä½œ](041_é€²éšè³‡æ–™åº«æ“ä½œ.md) | [ä¸‹ä¸€ç« ï¼šå¤šç·šç¨‹åŸºç¤](043_å¤šç·šç¨‹åŸºç¤.md)

# Python è³‡æ–™åº«æœ€ä½³å¯¦è¸ ğŸ¯

## è³‡æ–™åº«è¨­è¨ˆåŸå‰‡

### 1. è¦ç¯„åŒ–è¨­è¨ˆ

```python
from sqlalchemy import create_engine, Column, Integer, String, ForeignKey
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import relationship

Base = declarative_base()

# å¥½çš„è¨­è¨ˆï¼šå°‡åœ°å€ä¿¡æ¯è¦ç¯„åŒ–
class User(Base):
    __tablename__ = 'users'
    id = Column(Integer, primary_key=True)
    name = Column(String)
    email = Column(String, unique=True)
    addresses = relationship("Address", back_populates="user")

class Address(Base):
    __tablename__ = 'addresses'
    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, ForeignKey('users.id'))
    street = Column(String)
    city = Column(String)
    country = Column(String)
    user = relationship("User", back_populates="addresses")

# ä¸å¥½çš„è¨­è¨ˆï¼šå°‡åœ°å€ä¿¡æ¯ç›´æ¥æ”¾åœ¨ç”¨æˆ¶è¡¨ä¸­
class BadUser(Base):
    __tablename__ = 'bad_users'
    id = Column(Integer, primary_key=True)
    name = Column(String)
    email = Column(String, unique=True)
    street = Column(String)
    city = Column(String)
    country = Column(String)
```

### 2. ç´¢å¼•ç­–ç•¥

```python
from sqlalchemy import Index, text

class Product(Base):
    __tablename__ = 'products'
    id = Column(Integer, primary_key=True)
    name = Column(String)
    price = Column(Integer)
    category = Column(String)
    
    # å‰µå»ºè¤‡åˆç´¢å¼•
    __table_args__ = (
        Index('idx_name_category', 'name', 'category'),
        Index('idx_price', text('price DESC')),
    )

def optimize_query(session):
    # ä½¿ç”¨ç´¢å¼•çš„æŸ¥è©¢
    products = session.query(Product)\
        .filter(Product.category == 'electronics')\
        .order_by(Product.price.desc())\
        .all()
```

## æŸ¥è©¢å„ªåŒ–æŠ€å·§

### 1. é¸æ“‡æ€§ç´¢å¼•

```python
from sqlalchemy import func

class QueryOptimizer:
    def __init__(self, session):
        self.session = session
    
    def analyze_column_selectivity(self, model, column):
        """åˆ†æåˆ—çš„é¸æ“‡æ€§"""
        total_rows = self.session.query(func.count()).select_from(model).scalar()
        distinct_values = self.session.query(func.count(distinct(column))).scalar()
        selectivity = distinct_values / total_rows
        return selectivity
    
    def suggest_index(self, model, column, threshold=0.1):
        """æ ¹æ“šé¸æ“‡æ€§å»ºè­°æ˜¯å¦å‰µå»ºç´¢å¼•"""
        selectivity = self.analyze_column_selectivity(model, column)
        if selectivity > threshold:
            return f"å»ºè­°ç‚º {column} å‰µå»ºç´¢å¼•"
        return f"{column} çš„é¸æ“‡æ€§å¤ªä½ï¼Œä¸å»ºè­°å‰µå»ºç´¢å¼•"
```

### 2. æŸ¥è©¢è¨ˆåŠƒåˆ†æ

```python
from sqlalchemy import text

class QueryAnalyzer:
    def __init__(self, session):
        self.session = session
    
    def explain_query(self, query):
        """åˆ†ææŸ¥è©¢è¨ˆåŠƒ"""
        explain_stmt = f"EXPLAIN ANALYZE {query}"
        result = self.session.execute(text(explain_stmt))
        return result.fetchall()
    
    def optimize_query(self, query):
        """æä¾›æŸ¥è©¢å„ªåŒ–å»ºè­°"""
        plan = self.explain_query(query)
        suggestions = []
        
        for step in plan:
            if "Seq Scan" in step[0]:
                suggestions.append("è€ƒæ…®æ·»åŠ ç´¢å¼•é¿å…å…¨è¡¨æƒæ")
            if "Hash Join" in step[0]:
                suggestions.append("è€ƒæ…®ä½¿ç”¨ç´¢å¼•é€£æ¥ä»£æ›¿å“ˆå¸Œé€£æ¥")
        
        return suggestions
```

## æ€§èƒ½ç›£æ§

### 1. æŸ¥è©¢æ€§èƒ½è¿½è¹¤

```python
import time
from functools import wraps
from contextlib import contextmanager

@contextmanager
def query_timer():
    """æ¸¬é‡æŸ¥è©¢åŸ·è¡Œæ™‚é–“"""
    start = time.time()
    yield
    end = time.time()
    print(f"æŸ¥è©¢åŸ·è¡Œæ™‚é–“: {end - start:.4f} ç§’")

def monitor_query(func):
    """ç›£æ§æŸ¥è©¢æ€§èƒ½çš„è£é£¾å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        with query_timer():
            return func(*args, **kwargs)
    return wrapper

class QueryMonitor:
    def __init__(self):
        self.slow_queries = []
    
    @monitor_query
    def execute_query(self, session, query):
        return session.execute(query)
    
    def log_slow_query(self, query, execution_time):
        if execution_time > 1.0:  # è¶…é1ç§’çš„æŸ¥è©¢
            self.slow_queries.append({
                'query': query,
                'time': execution_time,
                'timestamp': datetime.now()
            })
```

### 2. é€£æ¥æ± ç›£æ§

```python
from sqlalchemy import event
from sqlalchemy.engine import Engine

class PoolMonitor:
    def __init__(self):
        self.active_connections = 0
        self.total_checkouts = 0
    
    def setup_monitoring(self, engine):
        @event.listens_for(engine, 'checkout')
        def on_checkout(dbapi_conn, conn_record, conn_proxy):
            self.active_connections += 1
            self.total_checkouts += 1
        
        @event.listens_for(engine, 'checkin')
        def on_checkin(dbapi_conn, conn_record):
            self.active_connections -= 1
    
    def get_stats(self):
        return {
            'active_connections': self.active_connections,
            'total_checkouts': self.total_checkouts
        }
```

## è³‡æ–™åº«ç¶­è­·

### 1. å‚™ä»½ç­–ç•¥

```python
import subprocess
from datetime import datetime

class DatabaseBackup:
    def __init__(self, db_url, backup_dir):
        self.db_url = db_url
        self.backup_dir = backup_dir
    
    def create_backup(self):
        """å‰µå»ºæ•¸æ“šåº«å‚™ä»½"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_file = f"{self.backup_dir}/backup_{timestamp}.sql"
        
        try:
            subprocess.run([
                'pg_dump',
                self.db_url,
                '-f', backup_file
            ], check=True)
            return f"å‚™ä»½æˆåŠŸ: {backup_file}"
        except subprocess.CalledProcessError as e:
            return f"å‚™ä»½å¤±æ•—: {e}"
    
    def restore_backup(self, backup_file):
        """å¾å‚™ä»½æ¢å¾©æ•¸æ“šåº«"""
        try:
            subprocess.run([
                'psql',
                self.db_url,
                '-f', backup_file
            ], check=True)
            return "æ¢å¾©æˆåŠŸ"
        except subprocess.CalledProcessError as e:
            return f"æ¢å¾©å¤±æ•—: {e}"
```

### 2. ç¶­è­·è¨ˆåŠƒ

```python
class DatabaseMaintenance:
    def __init__(self, session):
        self.session = session
    
    def vacuum_analyze(self):
        """åŸ·è¡ŒVACUUM ANALYZE"""
        self.session.execute(text("VACUUM ANALYZE"))
    
    def reindex_database(self):
        """é‡å»ºç´¢å¼•"""
        self.session.execute(text("REINDEX DATABASE current_database()"))
    
    def analyze_table_bloat(self):
        """åˆ†æè¡¨ç©ºé–“è†¨è„¹"""
        bloat_query = """
        SELECT schemaname, tablename, 
               pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) as total_size,
               pg_size_pretty(pg_table_size(schemaname||'.'||tablename)) as table_size,
               pg_size_pretty(pg_indexes_size(schemaname||'.'||tablename)) as index_size
        FROM pg_tables
        WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
        ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;
        """
        return self.session.execute(text(bloat_query)).fetchall()
```

## å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹

### 1. é«˜æ€§èƒ½æŸ¥è©¢æ¡†æ¶

```python
from typing import List, Any
from sqlalchemy import and_, or_

class QueryBuilder:
    def __init__(self, session, model):
        self.session = session
        self.model = model
        self.query = session.query(model)
        self._filters = []
        self._orders = []
        self._limit = None
        self._offset = None
    
    def filter(self, **kwargs):
        """æ·»åŠ éæ¿¾æ¢ä»¶"""
        for key, value in kwargs.items():
            if isinstance(value, (list, tuple)):
                self._filters.append(getattr(self.model, key).in_(value))
            else:
                self._filters.append(getattr(self.model, key) == value)
        return self
    
    def order_by(self, *args):
        """æ·»åŠ æ’åºæ¢ä»¶"""
        for arg in args:
            if arg.startswith('-'):
                self._orders.append(getattr(self.model, arg[1:]).desc())
            else:
                self._orders.append(getattr(self.model, arg).asc())
        return self
    
    def paginate(self, page: int, per_page: int):
        """åˆ†é """
        self._limit = per_page
        self._offset = (page - 1) * per_page
        return self
    
    def execute(self) -> List[Any]:
        """åŸ·è¡ŒæŸ¥è©¢"""
        if self._filters:
            self.query = self.query.filter(and_(*self._filters))
        
        if self._orders:
            self.query = self.query.order_by(*self._orders)
        
        if self._limit is not None:
            self.query = self.query.limit(self._limit)
        
        if self._offset is not None:
            self.query = self.query.offset(self._offset)
        
        return self.query.all()
```

### 2. è³‡æ–™åº«å¥åº·ç›£æ§ç³»çµ±

```python
import psutil
from datetime import datetime, timedelta

class DatabaseHealthMonitor:
    def __init__(self, engine, thresholds=None):
        self.engine = engine
        self.thresholds = thresholds or {
            'max_connections': 100,
            'slow_query_time': 1.0,
            'disk_usage_percent': 80
        }
    
    def check_connection_count(self):
        """æª¢æŸ¥ç•¶å‰é€£æ¥æ•¸"""
        result = self.engine.execute(text(
            "SELECT count(*) FROM pg_stat_activity"
        )).scalar()
        return {
            'current_connections': result,
            'status': 'OK' if result < self.thresholds['max_connections'] else 'WARNING'
        }
    
    def check_slow_queries(self):
        """æª¢æŸ¥æ…¢æŸ¥è©¢"""
        query = text("""
            SELECT query, total_time
            FROM pg_stat_statements
            WHERE total_time > :threshold
            ORDER BY total_time DESC
            LIMIT 10
        """)
        result = self.engine.execute(
            query, 
            threshold=self.thresholds['slow_query_time']
        ).fetchall()
        return {
            'slow_queries': [
                {'query': row[0], 'time': row[1]} 
                for row in result
            ]
        }
    
    def check_disk_usage(self):
        """æª¢æŸ¥ç£ç›¤ä½¿ç”¨æƒ…æ³"""
        disk_usage = psutil.disk_usage('/')
        return {
            'total': disk_usage.total,
            'used': disk_usage.used,
            'free': disk_usage.free,
            'percent': disk_usage.percent,
            'status': 'OK' if disk_usage.percent < self.thresholds['disk_usage_percent'] else 'WARNING'
        }
    
    def generate_health_report(self):
        """ç”Ÿæˆå¥åº·å ±å‘Š"""
        return {
            'timestamp': datetime.now(),
            'connections': self.check_connection_count(),
            'slow_queries': self.check_slow_queries(),
            'disk_usage': self.check_disk_usage()
        }
```

## ç·´ç¿’é¡Œ

1. **æŸ¥è©¢å„ªåŒ–å™¨**
   å¯¦ç¾ä¸€å€‹æŸ¥è©¢å„ªåŒ–å·¥å…·ï¼š
   - è‡ªå‹•åˆ†ææŸ¥è©¢è¨ˆåŠƒ
   - æä¾›å„ªåŒ–å»ºè­°
   - ç”Ÿæˆç´¢å¼•å»ºè­°
   - æª¢æ¸¬æ½›åœ¨å•é¡Œ

2. **æ€§èƒ½ç›£æ§ç³»çµ±**
   å‰µå»ºä¸€å€‹æ€§èƒ½ç›£æ§ç³»çµ±ï¼š
   - è¿½è¹¤æŸ¥è©¢åŸ·è¡Œæ™‚é–“
   - ç›£æ§è³‡æºä½¿ç”¨æƒ…æ³
   - ç”Ÿæˆæ€§èƒ½å ±å‘Š
   - ç™¼é€è­¦å ±é€šçŸ¥

3. **ç¶­è­·å·¥å…·**
   é–‹ç™¼ä¸€å€‹æ•¸æ“šåº«ç¶­è­·å·¥å…·ï¼š
   - è‡ªå‹•å‚™ä»½
   - ç´¢å¼•ç¶­è­·
   - ç©ºé–“å„ªåŒ–
   - çµ±è¨ˆä¿¡æ¯æ›´æ–°

## å°æé†’ ğŸ’¡

1. å®šæœŸæª¢æŸ¥æŸ¥è©¢æ€§èƒ½
2. é©ç•¶ä½¿ç”¨ç´¢å¼•
3. é¿å… N+1 æŸ¥è©¢å•é¡Œ
4. æ­£ç¢ºä½¿ç”¨äº‹å‹™
5. å¯¦æ–½å‚™ä»½ç­–ç•¥
6. ç›£æ§ç³»çµ±å¥åº·ç‹€æ³

[ä¸Šä¸€ç« ï¼šé€²éšè³‡æ–™åº«æ“ä½œ](041_é€²éšè³‡æ–™åº«æ“ä½œ.md) | [ä¸‹ä¸€ç« ï¼šå¤šç·šç¨‹åŸºç¤](043_å¤šç·šç¨‹åŸºç¤.md) 