[ä¸Šä¸€ç« ï¼šäº‹ä»¶é©…å‹•æ¶æ§‹](140_äº‹ä»¶é©…å‹•æ¶æ§‹.md) | [ä¸‹ä¸€ç« ï¼šç³»çµ±å¯è§€æ¸¬æ€§](142_ç³»çµ±å¯è§€æ¸¬æ€§.md)

# Python å¤§è¦æ¨¡æ•¸æ“šæµè™•ç† ğŸŒŠ

## 1. æµè™•ç†æ¡†æ¶

### 1.1 Apache Flink é›†æˆ

```python
from pyflink.datastream import StreamExecutionEnvironment
from pyflink.common.typeinfo import Types
from pyflink.datastream.connectors import FlinkKafkaConsumer, FlinkKafkaProducer
from typing import Dict, List
import json

class FlinkProcessor:
    """Flink è™•ç†å™¨"""
    def __init__(self):
        self.env = StreamExecutionEnvironment.get_execution_environment()
    
    def create_kafka_source(self,
                          topic: str,
                          bootstrap_servers: str,
                          group_id: str):
        """å‰µå»º Kafka æ•¸æ“šæº"""
        properties = {
            'bootstrap.servers': bootstrap_servers,
            'group.id': group_id,
            'auto.offset.reset': 'latest'
        }
        
        return FlinkKafkaConsumer(
            topics=topic,
            deserialization_schema=Types.STRING(),
            properties=properties
        )
    
    def create_kafka_sink(self,
                         topic: str,
                         bootstrap_servers: str):
        """å‰µå»º Kafka è¼¸å‡º"""
        properties = {
            'bootstrap.servers': bootstrap_servers,
            'transaction.timeout.ms': '5000'
        }
        
        return FlinkKafkaProducer(
            topic=topic,
            serialization_schema=Types.STRING(),
            producer_config=properties
        )
    
    def process_stream(self,
                      input_topic: str,
                      output_topic: str,
                      bootstrap_servers: str,
                      group_id: str):
        """è™•ç†æ•¸æ“šæµ"""
        # å‰µå»ºæ•¸æ“šæº
        source = self.create_kafka_source(
            input_topic,
            bootstrap_servers,
            group_id
        )
        
        # å‰µå»ºè¼¸å‡º
        sink = self.create_kafka_sink(
            output_topic,
            bootstrap_servers
        )
        
        # æ•¸æ“šè™•ç†
        self.env.add_source(source) \
            .map(lambda x: self._process_record(json.loads(x))) \
            .map(lambda x: json.dumps(x)) \
            .add_sink(sink)
        
        # åŸ·è¡Œä»»å‹™
        self.env.execute("Stream Processing Job")
    
    def _process_record(self, record: Dict) -> Dict:
        """è™•ç†å–®æ¢è¨˜éŒ„"""
        # å¯¦ç¾å…·é«”çš„è™•ç†é‚è¼¯
        return record
```

### 1.2 Apache Spark Streaming

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import *
from pyspark.sql.types import *
from typing import Dict, List

class SparkStreamProcessor:
    """Spark æµè™•ç†å™¨"""
    def __init__(self,
                 app_name: str,
                 master: str = "local[*]"):
        self.spark = SparkSession.builder \
            .appName(app_name) \
            .master(master) \
            .getOrCreate()
    
    def create_kafka_stream(self,
                          topic: str,
                          bootstrap_servers: str):
        """å‰µå»º Kafka æµ"""
        return self.spark.readStream \
            .format("kafka") \
            .option("kafka.bootstrap.servers", bootstrap_servers) \
            .option("subscribe", topic) \
            .load()
    
    def process_stream(self,
                      input_topic: str,
                      output_topic: str,
                      bootstrap_servers: str,
                      schema: StructType):
        """è™•ç†æ•¸æ“šæµ"""
        # è®€å–æ•¸æ“šæµ
        df = self.create_kafka_stream(
            input_topic,
            bootstrap_servers
        )
        
        # è§£æ JSON æ•¸æ“š
        parsed_df = df.select(
            from_json(
                col("value").cast("string"),
                schema
            ).alias("data")
        ).select("data.*")
        
        # è™•ç†æ•¸æ“š
        processed_df = self._process_data(parsed_df)
        
        # å¯«å…¥çµæœ
        query = processed_df \
            .selectExpr("to_json(struct(*)) as value") \
            .writeStream \
            .format("kafka") \
            .option("kafka.bootstrap.servers", bootstrap_servers) \
            .option("topic", output_topic) \
            .option("checkpointLocation", "/tmp/checkpoint") \
            .start()
        
        query.awaitTermination()
    
    def _process_data(self, df):
        """è™•ç†æ•¸æ“š"""
        # å¯¦ç¾å…·é«”çš„è™•ç†é‚è¼¯
        return df
```

## 2. å¯¦æ™‚åˆ†æ

### 2.1 æ™‚é–“çª—å£è™•ç†

```python
from datetime import datetime, timedelta
from typing import Dict, List, Optional
import pandas as pd

class WindowProcessor:
    """çª—å£è™•ç†å™¨"""
    def __init__(self,
                 window_size: timedelta,
                 slide_size: Optional[timedelta] = None):
        self.window_size = window_size
        self.slide_size = slide_size or window_size
        self.buffer: List[Dict] = []
    
    def process(self,
                event: Dict) -> Optional[Dict]:
        """è™•ç†äº‹ä»¶"""
        # æ·»åŠ äº‹ä»¶åˆ°ç·©è¡å€
        self.buffer.append(event)
        
        # ç²å–ç•¶å‰æ™‚é–“
        current_time = datetime.utcnow()
        
        # æ¸…ç†éæœŸæ•¸æ“š
        self.buffer = [
            e for e in self.buffer
            if current_time - datetime.fromisoformat(e['timestamp']) <= self.window_size
        ]
        
        # æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼è¨ˆç®—
        if self._should_trigger(current_time):
            return self._compute_window()
        
        return None
    
    def _should_trigger(self,
                       current_time: datetime) -> bool:
        """æª¢æŸ¥æ˜¯å¦éœ€è¦è§¸ç™¼è¨ˆç®—"""
        if not self.buffer:
            return False
        
        oldest_time = datetime.fromisoformat(self.buffer[0]['timestamp'])
        return current_time - oldest_time >= self.slide_size
    
    def _compute_window(self) -> Dict:
        """è¨ˆç®—çª—å£çµæœ"""
        df = pd.DataFrame(self.buffer)
        
        return {
            'start_time': df['timestamp'].min(),
            'end_time': df['timestamp'].max(),
            'count': len(df),
            'metrics': self._compute_metrics(df)
        }
    
    def _compute_metrics(self, df: pd.DataFrame) -> Dict:
        """è¨ˆç®—æŒ‡æ¨™"""
        # å¯¦ç¾å…·é«”çš„æŒ‡æ¨™è¨ˆç®—é‚è¼¯
        return {}
```

### 2.2 å¯¦æ™‚èšåˆ

```python
from collections import defaultdict
from typing import Dict, List, Tuple
import numpy as np

class StreamAggregator:
    """æµå¼èšåˆå™¨"""
    def __init__(self):
        self.aggregates = defaultdict(lambda: {
            'count': 0,
            'sum': 0,
            'min': float('inf'),
            'max': float('-inf'),
            'values': []
        })
    
    def update(self,
              key: str,
              value: float) -> Dict:
        """æ›´æ–°èšåˆå€¼"""
        agg = self.aggregates[key]
        
        # æ›´æ–°åŸºæœ¬çµ±è¨ˆ
        agg['count'] += 1
        agg['sum'] += value
        agg['min'] = min(agg['min'], value)
        agg['max'] = max(agg['max'], value)
        
        # æ›´æ–°å€¼åˆ—è¡¨ï¼ˆç”¨æ–¼è¨ˆç®—åˆ†ä½æ•¸ï¼‰
        agg['values'].append(value)
        
        # é™åˆ¶å­˜å„²çš„å€¼æ•¸é‡
        if len(agg['values']) > 1000:
            agg['values'] = self._reservoir_sampling(agg['values'], 1000)
        
        return self.get_metrics(key)
    
    def get_metrics(self, key: str) -> Dict:
        """ç²å–èšåˆæŒ‡æ¨™"""
        agg = self.aggregates[key]
        
        if agg['count'] == 0:
            return {}
        
        return {
            'count': agg['count'],
            'avg': agg['sum'] / agg['count'],
            'min': agg['min'],
            'max': agg['max'],
            'percentiles': self._calculate_percentiles(agg['values'])
        }
    
    def _reservoir_sampling(self,
                          values: List[float],
                          k: int) -> List[float]:
        """æ°´å¡˜æŠ½æ¨£"""
        result = values[:k]
        for i in range(k, len(values)):
            j = np.random.randint(0, i + 1)
            if j < k:
                result[j] = values[i]
        return result
    
    def _calculate_percentiles(self,
                             values: List[float]) -> Dict[str, float]:
        """è¨ˆç®—åˆ†ä½æ•¸"""
        if not values:
            return {}
        
        return {
            'p50': np.percentile(values, 50),
            'p90': np.percentile(values, 90),
            'p95': np.percentile(values, 95),
            'p99': np.percentile(values, 99)
        }
```

## 3. æ€§èƒ½å„ªåŒ–

### 3.1 ä¸¦è¡Œè™•ç†

```python
import asyncio
from typing import Callable, Dict, List
from concurrent.futures import ProcessPoolExecutor

class ParallelProcessor:
    """ä¸¦è¡Œè™•ç†å™¨"""
    def __init__(self,
                 num_workers: int = None):
        self.num_workers = num_workers or asyncio.get_event_loop()._default_executor._max_workers
        self.executor = ProcessPoolExecutor(max_workers=self.num_workers)
    
    async def process_batch(self,
                          items: List[Dict],
                          processor: Callable) -> List[Dict]:
        """ä¸¦è¡Œè™•ç†æ‰¹æ¬¡æ•¸æ“š"""
        loop = asyncio.get_event_loop()
        
        # å°‡æ•¸æ“šåˆ†ç‰‡
        chunk_size = max(1, len(items) // self.num_workers)
        chunks = [
            items[i:i + chunk_size]
            for i in range(0, len(items), chunk_size)
        ]
        
        # ä¸¦è¡Œè™•ç†
        tasks = [
            loop.run_in_executor(self.executor, processor, chunk)
            for chunk in chunks
        ]
        
        # ç­‰å¾…æ‰€æœ‰ä»»å‹™å®Œæˆ
        results = await asyncio.gather(*tasks)
        
        # åˆä½µçµæœ
        return [
            item
            for chunk_result in results
            for item in chunk_result
        ]
    
    def shutdown(self):
        """é—œé–‰è™•ç†å™¨"""
        self.executor.shutdown()
```

### 3.2 èƒŒå£“æ§åˆ¶

```python
from asyncio import Queue
from typing import Callable, Dict, Optional
import time

class BackpressureController:
    """èƒŒå£“æ§åˆ¶å™¨"""
    def __init__(self,
                 max_queue_size: int,
                 processing_rate: float):
        self.queue = Queue(maxsize=max_queue_size)
        self.processing_rate = processing_rate
        self.last_process_time = time.time()
    
    async def submit(self,
                    item: Dict) -> bool:
        """æäº¤é …ç›®"""
        try:
            await self.queue.put(item)
            return True
        except asyncio.QueueFull:
            return False
    
    async def process(self,
                     processor: Callable,
                     batch_size: int = 100) -> List[Dict]:
        """è™•ç†é …ç›®"""
        # æª¢æŸ¥è™•ç†é–“éš”
        current_time = time.time()
        time_diff = current_time - self.last_process_time
        
        if time_diff < 1.0 / self.processing_rate:
            await asyncio.sleep(1.0 / self.processing_rate - time_diff)
        
        # æ”¶é›†æ‰¹æ¬¡æ•¸æ“š
        items = []
        for _ in range(min(batch_size, self.queue.qsize())):
            if not self.queue.empty():
                items.append(await self.queue.get())
        
        if not items:
            return []
        
        # è™•ç†æ•¸æ“š
        results = await processor(items)
        
        # æ›´æ–°è™•ç†æ™‚é–“
        self.last_process_time = time.time()
        
        return results
```

## ç·´ç¿’é¡Œ ğŸƒâ€â™‚ï¸

1. å¯¦ç¾æµè™•ç†ç³»çµ±ï¼š
   - æ•¸æ“šæ¥å…¥
   - æµå¼è™•ç†
   - çª—å£è¨ˆç®—
   - ç‹€æ…‹ç®¡ç†
   - å®¹éŒ¯è™•ç†

2. é–‹ç™¼å¯¦æ™‚åˆ†ææ‡‰ç”¨ï¼š
   - æ™‚é–“åºåˆ—åˆ†æ
   - ç•°å¸¸æª¢æ¸¬
   - è¶¨å‹¢é æ¸¬
   - æ¨¡å¼è­˜åˆ¥
   - å¯¦æ™‚å ±è¡¨

3. å¯¦ç¾æ€§èƒ½å„ªåŒ–ï¼š
   - ä¸¦è¡Œè™•ç†
   - æ•¸æ“šåˆ†ç‰‡
   - å…§å­˜ç®¡ç†
   - èƒŒå£“æ§åˆ¶
   - è³‡æºèª¿å„ª

4. å‰µå»ºç›£æ§ç³»çµ±ï¼š
   - ååé‡ç›£æ§
   - å»¶é²ç›£æ§
   - è³‡æºä½¿ç”¨
   - éŒ¯èª¤è¿½è¸ª
   - æ€§èƒ½åˆ†æ

5. é–‹ç™¼æ¸¬è©¦æ¡†æ¶ï¼š
   - å–®å…ƒæ¸¬è©¦
   - æ€§èƒ½æ¸¬è©¦
   - å®¹éŒ¯æ¸¬è©¦
   - å£“åŠ›æ¸¬è©¦
   - é›†æˆæ¸¬è©¦

## å°çµ ğŸ“

- äº†è§£äº†æµè™•ç†æ¡†æ¶çš„ä½¿ç”¨æ–¹æ³•
- æŒæ¡äº†å¯¦æ™‚åˆ†æçš„æ ¸å¿ƒæŠ€è¡“
- å­¸æœƒäº†æ™‚é–“çª—å£çš„è™•ç†æ–¹å¼
- ç†è§£äº†æµå¼èšåˆçš„å¯¦ç¾åŸç†
- æŒæ¡äº†æ€§èƒ½å„ªåŒ–çš„é—œéµç­–ç•¥

## å»¶ä¼¸é–±è®€ ğŸ“š

1. æµè™•ç†ç³»çµ±è¨­è¨ˆ
2. å¯¦æ™‚åˆ†ææœ€ä½³å¯¦è¸
3. åˆ†å¸ƒå¼æµè™•ç†
4. æ™‚é–“åºåˆ—æ•¸æ“šè™•ç†
5. å¤§è¦æ¨¡æ•¸æ“šç³»çµ±

[ä¸Šä¸€ç« ï¼šäº‹ä»¶é©…å‹•æ¶æ§‹](140_äº‹ä»¶é©…å‹•æ¶æ§‹.md) | [ä¸‹ä¸€ç« ï¼šç³»çµ±å¯è§€æ¸¬æ€§](142_ç³»çµ±å¯è§€æ¸¬æ€§.md) 