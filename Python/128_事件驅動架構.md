[ä¸Šä¸€ç« ï¼šæœå‹™ç¶²æ ¼æ‡‰ç”¨](127_æœå‹™ç¶²æ ¼æ‡‰ç”¨.md) | [ä¸‹ä¸€ç« ï¼šå¤§è¦æ¨¡æ•¸æ“šæµè™•ç†](129_å¤§è¦æ¨¡æ•¸æ“šæµè™•ç†.md)

# Python äº‹ä»¶é©…å‹•æ¶æ§‹ ğŸ”„

## 1. äº‹ä»¶ç¸½ç·š

### 1.1 äº‹ä»¶ç™¼å¸ƒè¨‚é–±

```python
from typing import Dict, List, Callable, Any
import asyncio
from dataclasses import dataclass
import json
import logging

@dataclass
class Event:
    """äº‹ä»¶åŸºé¡"""
    event_type: str
    data: Dict[str, Any]
    timestamp: float
    source: str

class EventBus:
    def __init__(self):
        self.subscribers: Dict[str, List[Callable]] = {}
        self.logger = logging.getLogger("event_bus")
    
    def subscribe(self, event_type: str, handler: Callable):
        """è¨‚é–±äº‹ä»¶"""
        if event_type not in self.subscribers:
            self.subscribers[event_type] = []
        self.subscribers[event_type].append(handler)
    
    async def publish(self, event: Event):
        """ç™¼å¸ƒäº‹ä»¶"""
        handlers = self.subscribers.get(event.event_type, [])
        
        tasks = []
        for handler in handlers:
            try:
                if asyncio.iscoroutinefunction(handler):
                    tasks.append(handler(event))
                else:
                    tasks.append(
                        asyncio.get_event_loop().run_in_executor(
                            None, handler, event
                        )
                    )
            except Exception as e:
                self.logger.error(f"Error publishing event: {str(e)}")
        
        await asyncio.gather(*tasks, return_exceptions=True)
```

### 1.2 äº‹ä»¶æŒä¹…åŒ–

```python
import aioredis
import pickle
from datetime import datetime

class EventStore:
    def __init__(self, redis_url: str):
        self.redis = aioredis.from_url(redis_url)
    
    async def store_event(self, event: Event):
        """å­˜å„²äº‹ä»¶"""
        key = f"event:{event.event_type}:{datetime.now().isoformat()}"
        await self.redis.set(
            key,
            pickle.dumps(event),
            ex=86400  # 24å°æ™‚éæœŸ
        )
    
    async def get_events(self, event_type: str,
                        start_time: datetime,
                        end_time: datetime) -> List[Event]:
        """æŸ¥è©¢äº‹ä»¶"""
        keys = await self.redis.keys(f"event:{event_type}:*")
        events = []
        
        for key in keys:
            event_data = await self.redis.get(key)
            if event_data:
                event = pickle.loads(event_data)
                if start_time <= datetime.fromtimestamp(event.timestamp) <= end_time:
                    events.append(event)
        
        return sorted(events, key=lambda e: e.timestamp)
```

## 2. æ¶ˆæ¯éšŠåˆ—

### 2.1 æ¶ˆæ¯ç”Ÿç”¢è€…

```python
from typing import Optional
import aio_pika
import json

class MessageProducer:
    def __init__(self, amqp_url: str):
        self.amqp_url = amqp_url
        self.connection = None
        self.channel = None
    
    async def connect(self):
        """å»ºç«‹é€£æ¥"""
        self.connection = await aio_pika.connect_robust(self.amqp_url)
        self.channel = await self.connection.channel()
    
    async def publish_message(self, routing_key: str,
                            message: Dict,
                            exchange_name: Optional[str] = None):
        """ç™¼å¸ƒæ¶ˆæ¯"""
        if not self.connection or self.connection.is_closed:
            await self.connect()
        
        # å‰µå»ºäº¤æ›æ©Ÿ
        if exchange_name:
            exchange = await self.channel.declare_exchange(
                exchange_name,
                aio_pika.ExchangeType.TOPIC
            )
        else:
            exchange = self.channel.default_exchange
        
        # ç™¼é€æ¶ˆæ¯
        await exchange.publish(
            aio_pika.Message(
                body=json.dumps(message).encode(),
                content_type='application/json'
            ),
            routing_key=routing_key
        )
```

### 2.2 æ¶ˆæ¯æ¶ˆè²»è€…

```python
class MessageConsumer:
    def __init__(self, amqp_url: str):
        self.amqp_url = amqp_url
        self.connection = None
        self.channel = None
        self.handlers: Dict[str, Callable] = {}
    
    async def connect(self):
        """å»ºç«‹é€£æ¥"""
        self.connection = await aio_pika.connect_robust(self.amqp_url)
        self.channel = await self.connection.channel()
    
    async def subscribe(self, queue_name: str,
                       handler: Callable,
                       exchange_name: Optional[str] = None,
                       routing_key: str = '#'):
        """è¨‚é–±æ¶ˆæ¯"""
        if not self.connection or self.connection.is_closed:
            await self.connect()
        
        # å‰µå»ºéšŠåˆ—
        queue = await self.channel.declare_queue(queue_name, durable=True)
        
        # å¦‚æœæŒ‡å®šäº†äº¤æ›æ©Ÿï¼Œå‰‡ç¶å®š
        if exchange_name:
            exchange = await self.channel.declare_exchange(
                exchange_name,
                aio_pika.ExchangeType.TOPIC
            )
            await queue.bind(exchange, routing_key)
        
        self.handlers[queue_name] = handler
        
        # é–‹å§‹æ¶ˆè²»
        await queue.consume(self._message_handler)
    
    async def _message_handler(self, message: aio_pika.IncomingMessage):
        """è™•ç†æ¶ˆæ¯"""
        async with message.process():
            queue_name = message.routing_key
            handler = self.handlers.get(queue_name)
            
            if handler:
                try:
                    data = json.loads(message.body.decode())
                    if asyncio.iscoroutinefunction(handler):
                        await handler(data)
                    else:
                        await asyncio.get_event_loop().run_in_executor(
                            None, handler, data
                        )
                except Exception as e:
                    logging.error(f"Error processing message: {str(e)}")
```

## 3. åæ‡‰å¼ç·¨ç¨‹

### 3.1 åæ‡‰å¼æµ

```python
from typing import TypeVar, Generic
from rx import Observable, Subject
from rx import operators as ops

T = TypeVar('T')

class ReactiveStream(Generic[T]):
    def __init__(self):
        self.subject = Subject()
    
    def publish(self, value: T):
        """ç™¼å¸ƒå€¼"""
        self.subject.on_next(value)
    
    def subscribe(self, observer: Callable[[T], None]):
        """è¨‚é–±æµ"""
        return self.subject.subscribe(observer)
    
    def filter(self, predicate: Callable[[T], bool]) -> Observable:
        """éæ¿¾æµ"""
        return self.subject.pipe(
            ops.filter(predicate)
        )
    
    def map(self, transform: Callable[[T], Any]) -> Observable:
        """è½‰æ›æµ"""
        return self.subject.pipe(
            ops.map(transform)
        )
    
    def buffer(self, count: int) -> Observable:
        """ç·©è¡æµ"""
        return self.subject.pipe(
            ops.buffer_with_count(count)
        )
```

### 3.2 åæ‡‰å¼è™•ç†å™¨

```python
from rx.subject import Subject
from rx.scheduler import ThreadPoolScheduler
from concurrent.futures import ThreadPoolExecutor
import multiprocessing

class ReactiveProcessor:
    def __init__(self, worker_threads: int = None):
        self.worker_threads = worker_threads or multiprocessing.cpu_count()
        self.scheduler = ThreadPoolScheduler(ThreadPoolExecutor(self.worker_threads))
        self.input_stream = Subject()
        self.output_stream = Subject()
    
    def process(self, transform: Callable[[T], Any]):
        """è™•ç†æµæ•¸æ“š"""
        self.input_stream.pipe(
            ops.observe_on(self.scheduler),
            ops.map(transform),
            ops.catch(lambda e, _: Observable.empty())
        ).subscribe(self.output_stream)
    
    def handle_error(self, error_handler: Callable[[Exception], None]):
        """è™•ç†éŒ¯èª¤"""
        self.input_stream.pipe(
            ops.catch(lambda e, _: Observable.just(e))
        ).subscribe(error_handler)
    
    def backpressure(self, window_size: int,
                     window_time: int):
        """èƒŒå£“æ§åˆ¶"""
        return self.input_stream.pipe(
            ops.window_with_count_or_time(window_size, window_time),
            ops.flat_map(lambda w: w.pipe(
                ops.observe_on(self.scheduler)
            ))
        )
```

## ç·´ç¿’é¡Œ ğŸƒ

1. å¯¦ç¾ä¸€å€‹åˆ†å¸ƒå¼äº‹ä»¶ç¸½ç·šç³»çµ±ã€‚
2. é–‹ç™¼ä¸€å€‹å¯é çš„æ¶ˆæ¯éšŠåˆ—æ¶ˆè²»è€…ã€‚
3. è¨­è¨ˆä¸€å€‹åæ‡‰å¼æ•¸æ“šè™•ç†ç®¡é“ã€‚
4. å¯¦ç¾äº‹ä»¶æº¯æºå’ŒCQRSæ¨¡å¼ã€‚
5. å‰µå»ºä¸€å€‹äº‹ä»¶é©…å‹•çš„å¾®æœå‹™ç³»çµ±ã€‚

## å°çµ ğŸ“

- å­¸ç¿’äº†äº‹ä»¶é©…å‹•æ¶æ§‹çš„åŸºæœ¬æ¦‚å¿µ
- æŒæ¡äº†äº‹ä»¶ç¸½ç·šçš„å¯¦ç¾æ–¹æ³•
- ç†è§£äº†æ¶ˆæ¯éšŠåˆ—çš„ä½¿ç”¨
- å­¸æœƒäº†åæ‡‰å¼ç·¨ç¨‹
- äº†è§£äº†äº‹ä»¶é©…å‹•ç³»çµ±çš„è¨­è¨ˆæ¨¡å¼

## å»¶ä¼¸é–±è®€ ğŸ“š

1. Event-Driven Architecture
2. Message Queue Patterns
3. Reactive Programming in Python
4. Event Sourcing and CQRS
5. Distributed Event Systems

[ä¸Šä¸€ç« ï¼šæœå‹™ç¶²æ ¼æ‡‰ç”¨](127_æœå‹™ç¶²æ ¼æ‡‰ç”¨.md) | [ä¸‹ä¸€ç« ï¼šå¤§è¦æ¨¡æ•¸æ“šæµè™•ç†](129_å¤§è¦æ¨¡æ•¸æ“šæµè™•ç†.md) 