[上一章：生成對抗網絡應用](122_生成對抗網絡應用.md) | [下一章：聯邦學習基礎](124_聯邦學習基礎.md)

# Python 圖神經網絡 🕸️

## 1. 圖神經網絡基礎

### 1.1 圖數據結構

```python
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch_geometric.data import Data
from typing import List, Dict, Tuple
import networkx as nx
import numpy as np

class GraphDataset:
    def __init__(self):
        self.graphs = []
        self.labels = []
    
    def add_graph(self, nodes: torch.Tensor,
                  edges: torch.Tensor,
                  label: torch.Tensor):
        """添加圖數據"""
        graph = Data(
            x=nodes,
            edge_index=edges,
            y=label
        )
        self.graphs.append(graph)
        self.labels.append(label)
    
    def to_networkx(self, idx: int) -> nx.Graph:
        """轉換為NetworkX格式"""
        graph = self.graphs[idx]
        G = nx.Graph()
        
        # 添加節點
        for i in range(len(graph.x)):
            G.add_node(i, features=graph.x[i].numpy())
        
        # 添加邊
        edges = graph.edge_index.t().numpy()
        for edge in edges:
            G.add_edge(edge[0], edge[1])
        
        return G
```

### 1.2 圖卷積層

```python
class GraphConvolution(nn.Module):
    def __init__(self, in_features: int, out_features: int):
        super().__init__()
        self.weight = nn.Parameter(torch.FloatTensor(in_features, out_features))
        self.bias = nn.Parameter(torch.FloatTensor(out_features))
        self.reset_parameters()
    
    def reset_parameters(self):
        """初始化參數"""
        nn.init.kaiming_uniform_(self.weight)
        nn.init.zeros_(self.bias)
    
    def forward(self, x: torch.Tensor,
                adj: torch.Tensor) -> torch.Tensor:
        """前向傳播"""
        support = torch.mm(x, self.weight)
        output = torch.spmm(adj, support)
        return output + self.bias
```

## 2. 高級圖神經網絡模型

### 2.1 GraphSAGE實現

```python
class SAGEConv(nn.Module):
    def __init__(self, in_channels: int, out_channels: int,
                 aggr: str = 'mean'):
        super().__init__()
        self.in_channels = in_channels
        self.out_channels = out_channels
        self.aggr = aggr
        
        self.message_nn = nn.Linear(in_channels * 2, out_channels)
        self.update_nn = nn.Linear(in_channels + out_channels, out_channels)
    
    def forward(self, x: torch.Tensor,
                edge_index: torch.Tensor) -> torch.Tensor:
        """消息傳遞與更新"""
        # 收集鄰居信息
        row, col = edge_index
        x_neighbors = x[col]
        x_central = x[row]
        
        # 消息傳遞
        messages = self.message_nn(torch.cat([x_central, x_neighbors], dim=1))
        
        # 聚合
        if self.aggr == 'mean':
            aggr_messages = scatter_mean(messages, row, dim=0, dim_size=len(x))
        elif self.aggr == 'sum':
            aggr_messages = scatter_add(messages, row, dim=0, dim_size=len(x))
        else:
            raise ValueError(f'Unknown aggregation type: {self.aggr}')
        
        # 更新
        return self.update_nn(torch.cat([x, aggr_messages], dim=1))
```

### 2.2 GAT實現

```python
class GATConv(nn.Module):
    def __init__(self, in_features: int, out_features: int,
                 heads: int = 1, dropout: float = 0.6,
                 negative_slope: float = 0.2):
        super().__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.heads = heads
        self.dropout = dropout
        self.negative_slope = negative_slope
        
        self.weight = nn.Parameter(
            torch.FloatTensor(in_features, heads * out_features))
        self.att = nn.Parameter(torch.FloatTensor(1, heads, 2 * out_features))
        self.reset_parameters()
    
    def reset_parameters(self):
        """初始化參數"""
        nn.init.xavier_uniform_(self.weight)
        nn.init.xavier_uniform_(self.att)
    
    def forward(self, x: torch.Tensor,
                edge_index: torch.Tensor) -> torch.Tensor:
        """注意力機制的消息傳遞"""
        x = torch.mm(x, self.weight).view(-1, self.heads, self.out_features)
        
        # 計算注意力係數
        row, col = edge_index
        alpha = torch.cat([x[row], x[col]], dim=-1)
        alpha = (alpha * self.att).sum(dim=-1)
        alpha = F.leaky_relu(alpha, self.negative_slope)
        alpha = softmax(alpha, row, num_nodes=len(x))
        
        # 應用注意力
        out = scatter_add(
            alpha.view(-1, self.heads, 1) * x[col],
            row,
            dim=0,
            dim_size=len(x)
        )
        
        return out.mean(dim=1)
```

## 3. 圖表示學習

### 3.1 Node2Vec實現

```python
class Node2Vec:
    def __init__(self, graph: nx.Graph, dimensions: int = 128,
                 walk_length: int = 80, num_walks: int = 10,
                 p: float = 1.0, q: float = 1.0):
        self.graph = graph
        self.dimensions = dimensions
        self.walk_length = walk_length
        self.num_walks = num_walks
        self.p = p
        self.q = q
        
        self.preprocess_transition_probs()
    
    def node2vec_walk(self, start_node: int) -> List[int]:
        """生成隨機遊走序列"""
        walk = [start_node]
        
        while len(walk) < self.walk_length:
            cur = walk[-1]
            cur_nbrs = list(self.graph.neighbors(cur))
            if len(cur_nbrs) > 0:
                if len(walk) == 1:
                    walk.append(np.random.choice(cur_nbrs))
                else:
                    prev = walk[-2]
                    next_node = self._get_next_node(prev, cur, cur_nbrs)
                    walk.append(next_node)
            else:
                break
        
        return walk
    
    def _get_next_node(self, prev: int, cur: int,
                       neighbors: List[int]) -> int:
        """根據轉移概率選擇下一個節點"""
        probs = []
        for nbr in neighbors:
            if nbr == prev:
                probs.append(1/self.p)
            elif self.graph.has_edge(nbr, prev):
                probs.append(1)
            else:
                probs.append(1/self.q)
        
        probs = np.array(probs)
        probs = probs / probs.sum()
        
        return np.random.choice(neighbors, p=probs)
```

### 3.2 圖自編碼器

```python
class GraphAutoencoder(nn.Module):
    def __init__(self, input_dim: int, hidden_dim: int):
        super().__init__()
        
        # 編碼器
        self.encoder = nn.Sequential(
            GraphConvolution(input_dim, 2 * hidden_dim),
            nn.ReLU(),
            GraphConvolution(2 * hidden_dim, hidden_dim)
        )
        
        # 解碼器
        self.decoder = nn.Sequential(
            nn.Linear(hidden_dim, 2 * hidden_dim),
            nn.ReLU(),
            nn.Linear(2 * hidden_dim, input_dim),
            nn.Sigmoid()
        )
    
    def forward(self, x: torch.Tensor,
                adj: torch.Tensor) -> Tuple[torch.Tensor, torch.Tensor]:
        """前向傳播"""
        # 編碼
        z = self.encoder(x, adj)
        
        # 解碼
        adj_pred = torch.mm(z, z.t())
        x_pred = self.decoder(z)
        
        return x_pred, adj_pred
```

## 練習題 🏃

1. 實現一個基於GCN的節點分類器。
2. 使用GraphSAGE進行圖分類任務。
3. 開發一個基於GAT的鏈接預測系統。
4. 實現Node2Vec並可視化節點嵌入。
5. 設計一個圖自編碼器進行異常檢測。

## 小結 📝

- 學習了圖神經網絡的基本概念
- 掌握了不同類型的圖卷積層
- 理解了注意力機制在圖上的應用
- 學會了圖表示學習方法
- 了解了圖自編碼器的實現

## 延伸閱讀 📚

1. Graph Neural Networks: Foundations and Applications
2. Deep Learning on Graphs
3. Graph Representation Learning
4. Network Science
5. Graph Mining Algorithms

[上一章：生成對抗網絡應用](122_生成對抗網絡應用.md) | [下一章：聯邦學習基礎](124_聯邦學習基礎.md) 