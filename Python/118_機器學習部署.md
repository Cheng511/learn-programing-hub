[上一章：雲端數據庫整合](117_雲端數據庫整合.md) | [下一章：AI模型優化](119_AI模型優化.md)

# Python 機器學習部署 🚀

## 1. 模型序列化與加載

### 1.1 模型保存與加載

```python
import joblib
import pickle
from typing import Any, Dict
import os

class ModelSerializer:
    @staticmethod
    def save_model(model: Any, path: str, format: str = 'joblib'):
        """保存模型"""
        os.makedirs(os.path.dirname(path), exist_ok=True)
        
        if format == 'joblib':
            joblib.dump(model, path)
        elif format == 'pickle':
            with open(path, 'wb') as f:
                pickle.dump(model, f)
        else:
            raise ValueError(f"Unsupported format: {format}")
    
    @staticmethod
    def load_model(path: str, format: str = 'joblib') -> Any:
        """加載模型"""
        if format == 'joblib':
            return joblib.load(path)
        elif format == 'pickle':
            with open(path, 'rb') as f:
                return pickle.load(f)
        else:
            raise ValueError(f"Unsupported format: {format}")
```

### 1.2 模型版本控制

```python
from datetime import datetime
import json
from typing import Optional

class ModelVersionControl:
    def __init__(self, base_path: str):
        self.base_path = base_path
        self.metadata_file = os.path.join(base_path, 'model_metadata.json')
        self.metadata = self._load_metadata()
    
    def save_model_version(self, model: Any, version: str, 
                          metrics: Dict, description: str = ""):
        """保存模型版本"""
        model_path = os.path.join(self.base_path, f"model_v{version}.joblib")
        ModelSerializer.save_model(model, model_path)
        
        self.metadata['versions'][version] = {
            'path': model_path,
            'metrics': metrics,
            'description': description,
            'created_at': datetime.now().isoformat()
        }
        self._save_metadata()
    
    def get_model_version(self, version: str) -> Optional[Any]:
        """獲取特定版本的模型"""
        if version in self.metadata['versions']:
            path = self.metadata['versions'][version]['path']
            return ModelSerializer.load_model(path)
        return None
```

## 2. REST API 部署

### 2.1 FastAPI 服務

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import numpy as np
from typing import List, Dict

class PredictionRequest(BaseModel):
    features: List[float]

class ModelService:
    def __init__(self, model_path: str):
        self.model = ModelSerializer.load_model(model_path)
        self.app = FastAPI()
        self.setup_routes()
    
    def setup_routes(self):
        """設置API路由"""
        @self.app.post("/predict")
        async def predict(request: PredictionRequest):
            try:
                features = np.array(request.features).reshape(1, -1)
                prediction = self.model.predict(features)
                return {"prediction": prediction.tolist()}
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))
        
        @self.app.get("/model/info")
        async def model_info():
            return {
                "model_type": type(self.model).__name__,
                "feature_count": self.model.n_features_in_
            }
```

### 2.2 模型監控

```python
import time
from datetime import datetime
from collections import deque

class ModelMonitor:
    def __init__(self, window_size: int = 1000):
        self.predictions = deque(maxlen=window_size)
        self.latencies = deque(maxlen=window_size)
        self.errors = deque(maxlen=window_size)
    
    def log_prediction(self, input_data: Any, prediction: Any, 
                      latency: float, error: Optional[str] = None):
        """記錄預測信息"""
        timestamp = datetime.now()
        self.predictions.append({
            'timestamp': timestamp,
            'input': input_data,
            'prediction': prediction,
            'latency': latency
        })
        
        self.latencies.append(latency)
        
        if error:
            self.errors.append({
                'timestamp': timestamp,
                'error': error,
                'input': input_data
            })
    
    def get_statistics(self) -> Dict:
        """獲取監控統計信息"""
        return {
            'avg_latency': np.mean(self.latencies),
            'max_latency': np.max(self.latencies),
            'error_rate': len(self.errors) / len(self.predictions),
            'total_predictions': len(self.predictions)
        }
```

## 3. 容器化部署

### 3.1 Docker 配置

```python
class DockerConfig:
    @staticmethod
    def generate_dockerfile(requirements_path: str, 
                          model_path: str,
                          port: int = 8000) -> str:
        """生成Dockerfile"""
        return f"""
FROM python:3.8-slim

WORKDIR /app

COPY {requirements_path} /app/requirements.txt
RUN pip install -r requirements.txt

COPY {model_path} /app/model/
COPY . /app/

EXPOSE {port}

CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "{port}"]
"""
    
    @staticmethod
    def generate_compose_file(service_name: str, 
                            image_name: str,
                            port: int = 8000) -> str:
        """生成docker-compose.yml"""
        return f"""
version: '3'
services:
  {service_name}:
    build: .
    image: {image_name}
    ports:
      - "{port}:{port}"
    volumes:
      - ./model:/app/model
    environment:
      - MODEL_PATH=/app/model/model.joblib
"""
```

### 3.2 Kubernetes 部署

```python
from kubernetes import client, config
from typing import Dict, List

class KubernetesDeployer:
    def __init__(self):
        config.load_kube_config()
        self.api = client.AppsV1Api()
    
    def create_deployment(self, name: str, image: str, 
                         replicas: int = 3) -> Dict:
        """創建Kubernetes部署"""
        deployment = client.V1Deployment(
            metadata=client.V1ObjectMeta(name=name),
            spec=client.V1DeploymentSpec(
                replicas=replicas,
                selector=client.V1LabelSelector(
                    match_labels={"app": name}
                ),
                template=client.V1PodTemplateSpec(
                    metadata=client.V1ObjectMeta(
                        labels={"app": name}
                    ),
                    spec=client.V1PodSpec(
                        containers=[
                            client.V1Container(
                                name=name,
                                image=image,
                                ports=[client.V1ContainerPort(container_port=8000)]
                            )
                        ]
                    )
                )
            )
        )
        
        return self.api.create_namespaced_deployment(
            body=deployment,
            namespace="default"
        )
```

## 4. 模型服務擴展

### 4.1 負載均衡

```python
from typing import List, Dict
import random

class LoadBalancer:
    def __init__(self, endpoints: List[str]):
        self.endpoints = endpoints
        self.current = 0
    
    def round_robin(self) -> str:
        """輪詢算法"""
        endpoint = self.endpoints[self.current]
        self.current = (self.current + 1) % len(self.endpoints)
        return endpoint
    
    def random_select(self) -> str:
        """隨機選擇"""
        return random.choice(self.endpoints)
    
    def weighted_select(self, weights: Dict[str, float]) -> str:
        """加權選擇"""
        total = sum(weights.values())
        r = random.uniform(0, total)
        upto = 0
        for endpoint, weight in weights.items():
            if upto + weight >= r:
                return endpoint
            upto += weight
        return self.endpoints[-1]
```

### 4.2 自動擴展

```python
import psutil
from typing import Dict, Optional

class AutoScaler:
    def __init__(self, min_replicas: int = 1, max_replicas: int = 10,
                 cpu_threshold: float = 70.0):
        self.min_replicas = min_replicas
        self.max_replicas = max_replicas
        self.cpu_threshold = cpu_threshold
        self.current_replicas = min_replicas
    
    def check_scaling_needs(self) -> Optional[int]:
        """檢查是否需要擴展"""
        cpu_percent = psutil.cpu_percent()
        
        if cpu_percent > self.cpu_threshold and \
           self.current_replicas < self.max_replicas:
            return self.current_replicas + 1
        elif cpu_percent < self.cpu_threshold / 2 and \
             self.current_replicas > self.min_replicas:
            return self.current_replicas - 1
        
        return None
    
    def scale(self, new_replicas: int):
        """執行擴展操作"""
        self.current_replicas = new_replicas
        # 實現具體的擴展邏輯
```

## 練習題 🏃

1. 實現一個完整的模型部署流程，包括序列化、API服務和容器化。
2. 開發一個模型版本控制系統，支持回滾和A/B測試。
3. 設計一個自動擴展系統，根據負載自動調整服務實例數。
4. 實現一個模型監控儀表板，顯示性能指標和預測統計。
5. 創建一個多模型集成服務，支持不同類型的模型部署。

## 小結 📝

- 學習了模型序列化和版本控制
- 掌握了REST API部署方法
- 理解了容器化部署流程
- 學會了負載均衡和自動擴展
- 了解了模型監控和維護

## 延伸閱讀 📚

1. MLOps: Machine Learning Operations
2. Docker and Kubernetes in Action
3. FastAPI for Machine Learning
4. Scalable Machine Learning Deployment
5. Model Monitoring Best Practices

[上一章：雲端數據庫整合](117_雲端數據庫整合.md) | [下一章：AI模型優化](119_AI模型優化.md) 