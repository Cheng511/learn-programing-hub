[ä¸Šä¸€ç« ï¼šAIæ¨¡å‹å„ªåŒ–](119_AIæ¨¡å‹å„ªåŒ–.md)

# Python ç«¯åˆ°ç«¯AIæ‡‰ç”¨é–‹ç™¼ ğŸ¯

## 1. é …ç›®æ¶æ§‹è¨­è¨ˆ

### 1.1 æ¨¡å¡ŠåŒ–è¨­è¨ˆ

```python
from abc import ABC, abstractmethod
from typing import Dict, List, Any
import logging

class AIProject:
    def __init__(self, config: Dict):
        self.config = config
        self.data_loader = None
        self.preprocessor = None
        self.model = None
        self.trainer = None
        self.evaluator = None
        
        self.setup_logging()
        self.initialize_components()
    
    def setup_logging(self):
        """è¨­ç½®æ—¥èªŒ"""
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        )
        self.logger = logging.getLogger(__name__)
    
    def initialize_components(self):
        """åˆå§‹åŒ–å„å€‹çµ„ä»¶"""
        self.data_loader = self._create_data_loader()
        self.preprocessor = self._create_preprocessor()
        self.model = self._create_model()
        self.trainer = self._create_trainer()
        self.evaluator = self._create_evaluator()
```

### 1.2 é…ç½®ç®¡ç†

```python
import yaml
from pathlib import Path
from typing import Dict, Any

class ConfigManager:
    def __init__(self, config_path: str):
        self.config_path = Path(config_path)
        self.config = self._load_config()
    
    def _load_config(self) -> Dict:
        """åŠ è¼‰é…ç½®æ–‡ä»¶"""
        with open(self.config_path, 'r') as f:
            return yaml.safe_load(f)
    
    def get(self, key: str, default: Any = None) -> Any:
        """ç²å–é…ç½®å€¼"""
        keys = key.split('.')
        value = self.config
        
        for k in keys:
            if isinstance(value, dict):
                value = value.get(k)
            else:
                return default
            
        return value if value is not None else default
    
    def update(self, key: str, value: Any):
        """æ›´æ–°é…ç½®"""
        keys = key.split('.')
        config = self.config
        
        for k in keys[:-1]:
            config = config.setdefault(k, {})
        
        config[keys[-1]] = value
        self._save_config()
```

## 2. æ•¸æ“šè™•ç†æµæ°´ç·š

### 2.1 æ•¸æ“šåŠ è¼‰èˆ‡é è™•ç†

```python
import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from typing import Tuple, Optional

class DataPipeline:
    def __init__(self, config: Dict):
        self.config = config
        self.scaler = StandardScaler()
        
    def load_data(self) -> Tuple[pd.DataFrame, pd.DataFrame]:
        """åŠ è¼‰æ•¸æ“š"""
        train_path = self.config['data']['train_path']
        test_path = self.config['data']['test_path']
        
        train_data = pd.read_csv(train_path)
        test_data = pd.read_csv(test_path)
        
        return train_data, test_data
    
    def preprocess(self, data: pd.DataFrame,
                   is_training: bool = True) -> np.ndarray:
        """æ•¸æ“šé è™•ç†"""
        # è™•ç†ç¼ºå¤±å€¼
        data = self._handle_missing_values(data)
        
        # ç‰¹å¾µå·¥ç¨‹
        data = self._feature_engineering(data)
        
        # æ¨™æº–åŒ–
        if is_training:
            data = self.scaler.fit_transform(data)
        else:
            data = self.scaler.transform(data)
        
        return data
```

### 2.2 ç‰¹å¾µå·¥ç¨‹

```python
from sklearn.feature_selection import SelectKBest, f_classif
from typing import List

class FeatureEngineer:
    def __init__(self, config: Dict):
        self.config = config
        self.feature_selector = None
        
    def create_features(self, data: pd.DataFrame) -> pd.DataFrame:
        """å‰µå»ºæ–°ç‰¹å¾µ"""
        # å¯¦ç¾ç‰¹å¾µå‰µå»ºé‚è¼¯
        return data
    
    def select_features(self, X: np.ndarray, y: np.ndarray,
                       n_features: int) -> np.ndarray:
        """ç‰¹å¾µé¸æ“‡"""
        self.feature_selector = SelectKBest(
            score_func=f_classif,
            k=n_features
        )
        return self.feature_selector.fit_transform(X, y)
    
    def get_feature_importance(self) -> List[Tuple[str, float]]:
        """ç²å–ç‰¹å¾µé‡è¦æ€§"""
        if self.feature_selector is None:
            raise ValueError("Must run select_features first")
        
        scores = self.feature_selector.scores_
        features = self.config['features']
        
        return sorted(zip(features, scores),
                     key=lambda x: x[1],
                     reverse=True)
```

## 3. æ¨¡å‹é–‹ç™¼èˆ‡è¨“ç·´

### 3.1 æ¨¡å‹æ¶æ§‹

```python
import torch
import torch.nn as nn
from typing import List

class CustomModel(nn.Module):
    def __init__(self, input_dim: int, hidden_dims: List[int],
                 output_dim: int):
        super().__init__()
        
        layers = []
        prev_dim = input_dim
        
        # æ§‹å»ºéš±è—å±¤
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.BatchNorm1d(hidden_dim),
                nn.Dropout(0.5)
            ])
            prev_dim = hidden_dim
        
        # è¼¸å‡ºå±¤
        layers.append(nn.Linear(prev_dim, output_dim))
        
        self.network = nn.Sequential(*layers)
    
    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.network(x)
```

### 3.2 è¨“ç·´æµç¨‹

```python
from torch.utils.data import DataLoader
from typing import Dict, Optional

class ModelTrainer:
    def __init__(self, model: nn.Module, config: Dict):
        self.model = model
        self.config = config
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        
        self.optimizer = self._create_optimizer()
        self.scheduler = self._create_scheduler()
        self.criterion = self._create_criterion()
    
    def train_epoch(self, dataloader: DataLoader) -> Dict[str, float]:
        """è¨“ç·´ä¸€å€‹epoch"""
        self.model.train()
        total_loss = 0
        correct = 0
        total = 0
        
        for batch_idx, (data, targets) in enumerate(dataloader):
            data, targets = data.to(self.device), targets.to(self.device)
            
            self.optimizer.zero_grad()
            outputs = self.model(data)
            loss = self.criterion(outputs, targets)
            
            loss.backward()
            self.optimizer.step()
            
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            total += targets.size(0)
            correct += predicted.eq(targets).sum().item()
        
        return {
            'loss': total_loss / len(dataloader),
            'accuracy': 100. * correct / total
        }
```

## 4. éƒ¨ç½²èˆ‡ç›£æ§

### 4.1 APIæœå‹™

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict

class PredictionService:
    def __init__(self, model: nn.Module, preprocessor: DataPipeline):
        self.model = model
        self.preprocessor = preprocessor
        self.app = FastAPI()
        self.setup_routes()
    
    def setup_routes(self):
        """è¨­ç½®APIè·¯ç”±"""
        @self.app.post("/predict")
        async def predict(data: Dict):
            try:
                # é è™•ç†
                processed_data = self.preprocessor.preprocess(
                    pd.DataFrame([data]),
                    is_training=False
                )
                
                # é æ¸¬
                with torch.no_grad():
                    input_tensor = torch.FloatTensor(processed_data)
                    prediction = self.model(input_tensor)
                
                return {"prediction": prediction.numpy().tolist()}
            
            except Exception as e:
                raise HTTPException(status_code=400, detail=str(e))
```

### 4.2 æ€§èƒ½ç›£æ§

```python
import time
from datetime import datetime
import psutil
import GPUtil
from typing import Dict, List

class PerformanceMonitor:
    def __init__(self):
        self.metrics = []
    
    def collect_metrics(self) -> Dict:
        """æ”¶é›†æ€§èƒ½æŒ‡æ¨™"""
        cpu_percent = psutil.cpu_percent()
        memory = psutil.virtual_memory()
        
        gpu_metrics = []
        try:
            gpus = GPUtil.getGPUs()
            for gpu in gpus:
                gpu_metrics.append({
                    'id': gpu.id,
                    'load': gpu.load,
                    'memory_used': gpu.memoryUsed,
                    'memory_total': gpu.memoryTotal
                })
        except:
            pass
        
        metrics = {
            'timestamp': datetime.now().isoformat(),
            'cpu_percent': cpu_percent,
            'memory_percent': memory.percent,
            'gpu_metrics': gpu_metrics
        }
        
        self.metrics.append(metrics)
        return metrics
    
    def get_average_metrics(self, window: int = 100) -> Dict:
        """ç²å–å¹³å‡æŒ‡æ¨™"""
        if not self.metrics:
            return {}
        
        recent_metrics = self.metrics[-window:]
        avg_cpu = sum(m['cpu_percent'] for m in recent_metrics) / len(recent_metrics)
        avg_memory = sum(m['memory_percent'] for m in recent_metrics) / len(recent_metrics)
        
        return {
            'avg_cpu_percent': avg_cpu,
            'avg_memory_percent': avg_memory
        }
```

## ç·´ç¿’é¡Œ ğŸƒ

1. è¨­è¨ˆä¸¦å¯¦ç¾ä¸€å€‹å®Œæ•´çš„AIæ‡‰ç”¨é …ç›®æ¶æ§‹ã€‚
2. é–‹ç™¼ä¸€å€‹ç«¯åˆ°ç«¯çš„æ•¸æ“šè™•ç†æµæ°´ç·šã€‚
3. å¯¦ç¾ä¸€å€‹å¯æ“´å±•çš„æ¨¡å‹è¨“ç·´æ¡†æ¶ã€‚
4. éƒ¨ç½²ä¸€å€‹ç”Ÿç”¢ç´šåˆ¥çš„AIæœå‹™ã€‚
5. å»ºç«‹ä¸€å€‹å®Œæ•´çš„æ€§èƒ½ç›£æ§ç³»çµ±ã€‚

## å°çµ ğŸ“

- å­¸ç¿’äº†AIé …ç›®æ¶æ§‹è¨­è¨ˆ
- æŒæ¡äº†æ•¸æ“šè™•ç†æµæ°´ç·šé–‹ç™¼
- ç†è§£äº†æ¨¡å‹é–‹ç™¼èˆ‡è¨“ç·´æµç¨‹
- å­¸æœƒäº†APIæœå‹™éƒ¨ç½²æ–¹æ³•
- äº†è§£äº†æ€§èƒ½ç›£æ§å¯¦ç¾

## å»¶ä¼¸é–±è®€ ğŸ“š

1. Production Machine Learning Systems
2. Building ML Powered Applications
3. Designing Machine Learning Systems
4. MLOps Engineering at Scale
5. Monitoring Machine Learning Models in Production

[ä¸Šä¸€ç« ï¼šAIæ¨¡å‹å„ªåŒ–](119_AIæ¨¡å‹å„ªåŒ–.md) 