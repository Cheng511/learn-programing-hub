[上一章：大規模數據流處理](129_大規模數據流處理.md)

# Python 系統可觀測性 🔍

## 1. 指標收集

### 1.1 指標收集器

```python
from typing import Dict, List, Any
import time
from dataclasses import dataclass
import prometheus_client as prom
import threading

@dataclass
class Metric:
    """指標定義"""
    name: str
    description: str
    type: str
    labels: List[str] = None

class MetricsCollector:
    def __init__(self):
        self.metrics: Dict[str, Any] = {}
        self.lock = threading.Lock()
    
    def create_counter(self, metric: Metric):
        """創建計數器"""
        with self.lock:
            if metric.name not in self.metrics:
                self.metrics[metric.name] = prom.Counter(
                    metric.name,
                    metric.description,
                    metric.labels
                )
    
    def create_gauge(self, metric: Metric):
        """創建量表"""
        with self.lock:
            if metric.name not in self.metrics:
                self.metrics[metric.name] = prom.Gauge(
                    metric.name,
                    metric.description,
                    metric.labels
                )
    
    def create_histogram(self, metric: Metric,
                        buckets: List[float] = None):
        """創建直方圖"""
        with self.lock:
            if metric.name not in self.metrics:
                self.metrics[metric.name] = prom.Histogram(
                    metric.name,
                    metric.description,
                    metric.labels,
                    buckets=buckets
                )
    
    def increment_counter(self, name: str,
                         value: float = 1,
                         labels: Dict[str, str] = None):
        """增加計數器"""
        if name in self.metrics:
            if labels:
                self.metrics[name].labels(**labels).inc(value)
            else:
                self.metrics[name].inc(value)
    
    def set_gauge(self, name: str,
                  value: float,
                  labels: Dict[str, str] = None):
        """設置量表值"""
        if name in self.metrics:
            if labels:
                self.metrics[name].labels(**labels).set(value)
            else:
                self.metrics[name].set(value)
    
    def observe_histogram(self, name: str,
                         value: float,
                         labels: Dict[str, str] = None):
        """觀察直方圖值"""
        if name in self.metrics:
            if labels:
                self.metrics[name].labels(**labels).observe(value)
            else:
                self.metrics[name].observe(value)
```

### 1.2 性能指標

```python
import psutil
import os
from typing import Dict

class SystemMetrics:
    def __init__(self, collector: MetricsCollector):
        self.collector = collector
        self.setup_metrics()
    
    def setup_metrics(self):
        """設置系統指標"""
        self.collector.create_gauge(Metric(
            name='system_cpu_usage',
            description='CPU usage percentage',
            type='gauge'
        ))
        
        self.collector.create_gauge(Metric(
            name='system_memory_usage',
            description='Memory usage percentage',
            type='gauge'
        ))
        
        self.collector.create_gauge(Metric(
            name='system_disk_usage',
            description='Disk usage percentage',
            type='gauge',
            labels=['path']
        ))
    
    def collect_metrics(self):
        """收集系統指標"""
        # CPU使用率
        cpu_percent = psutil.cpu_percent()
        self.collector.set_gauge('system_cpu_usage', cpu_percent)
        
        # 內存使用率
        memory = psutil.virtual_memory()
        self.collector.set_gauge('system_memory_usage', memory.percent)
        
        # 磁盤使用率
        for partition in psutil.disk_partitions():
            try:
                usage = psutil.disk_usage(partition.mountpoint)
                self.collector.set_gauge(
                    'system_disk_usage',
                    usage.percent,
                    {'path': partition.mountpoint}
                )
            except Exception:
                continue
```

## 2. 日誌管理

### 2.1 結構化日誌

```python
import logging
import json
from datetime import datetime
from typing import Any, Optional

class StructuredLogger:
    def __init__(self, name: str,
                 level: int = logging.INFO):
        self.logger = logging.getLogger(name)
        self.logger.setLevel(level)
        
        # 添加控制台處理器
        handler = logging.StreamHandler()
        handler.setFormatter(
            logging.Formatter('%(message)s')
        )
        self.logger.addHandler(handler)
    
    def log(self, level: int,
            message: str,
            **kwargs):
        """記錄結構化日誌"""
        log_entry = {
            'timestamp': datetime.now().isoformat(),
            'level': logging.getLevelName(level),
            'message': message,
            **kwargs
        }
        
        self.logger.log(
            level,
            json.dumps(log_entry)
        )
    
    def info(self, message: str, **kwargs):
        self.log(logging.INFO, message, **kwargs)
    
    def error(self, message: str, **kwargs):
        self.log(logging.ERROR, message, **kwargs)
    
    def warning(self, message: str, **kwargs):
        self.log(logging.WARNING, message, **kwargs)
    
    def debug(self, message: str, **kwargs):
        self.log(logging.DEBUG, message, **kwargs)
```

### 2.2 日誌聚合

```python
import aiohttp
import asyncio
from typing import List

class LogAggregator:
    def __init__(self, elasticsearch_url: str):
        self.elasticsearch_url = elasticsearch_url
        self.buffer: List[Dict] = []
        self.buffer_size = 100
        self.flush_interval = 5  # 秒
    
    async def setup(self):
        """設置日誌聚合器"""
        self.session = aiohttp.ClientSession()
        asyncio.create_task(self._periodic_flush())
    
    async def add_log(self, log_entry: Dict):
        """添加日誌"""
        self.buffer.append(log_entry)
        
        if len(self.buffer) >= self.buffer_size:
            await self.flush()
    
    async def flush(self):
        """刷新日誌到Elasticsearch"""
        if not self.buffer:
            return
        
        bulk_data = []
        for entry in self.buffer:
            bulk_data.extend([
                {'index': {'_index': 'logs'}},
                entry
            ])
        
        try:
            async with self.session.post(
                f"{self.elasticsearch_url}/_bulk",
                json=bulk_data,
                headers={'Content-Type': 'application/x-ndjson'}
            ) as response:
                if response.status >= 400:
                    print(f"Error flushing logs: {await response.text()}")
        except Exception as e:
            print(f"Error sending logs: {str(e)}")
        finally:
            self.buffer.clear()
    
    async def _periodic_flush(self):
        """定期刷新日誌"""
        while True:
            await asyncio.sleep(self.flush_interval)
            await self.flush()
```

## 3. 分布式追踪

### 3.1 追踪系統

```python
from opentelemetry import trace
from opentelemetry.trace import Status, StatusCode
from opentelemetry.trace.span import Span
from contextlib import contextmanager
import time

class TracingSystem:
    def __init__(self, service_name: str):
        self.tracer = trace.get_tracer(service_name)
    
    @contextmanager
    def start_span(self, name: str,
                   attributes: Dict[str, str] = None):
        """開始一個追踪範圍"""
        with self.tracer.start_as_current_span(
            name,
            attributes=attributes
        ) as span:
            try:
                yield span
            except Exception as e:
                span.set_status(Status(StatusCode.ERROR))
                span.record_exception(e)
                raise
    
    def add_event(self, span: Span,
                  name: str,
                  attributes: Dict[str, str] = None):
        """添加事件"""
        span.add_event(
            name,
            attributes=attributes,
            timestamp=time.time_ns()
        )
    
    def set_attribute(self, span: Span,
                     key: str,
                     value: str):
        """設置屬性"""
        span.set_attribute(key, value)
```

### 3.2 追踪中間件

```python
from fastapi import Request
from opentelemetry.trace import SpanKind
import asyncio

class TracingMiddleware:
    def __init__(self, app, tracer: TracingSystem):
        self.app = app
        self.tracer = tracer
    
    async def __call__(self, request: Request, call_next):
        with self.tracer.start_span(
            f"{request.method} {request.url.path}",
            {
                'http.method': request.method,
                'http.url': str(request.url),
                'http.scheme': request.url.scheme
            }
        ) as span:
            try:
                response = await call_next(request)
                span.set_attribute(
                    'http.status_code',
                    response.status_code
                )
                return response
            except Exception as e:
                span.record_exception(e)
                raise
```

## 練習題 🏃

1. 實現一個完整的指標收集系統。
2. 開發一個分布式日誌聚合器。
3. 設計一個追踪系統的可視化界面。
4. 實現自定義的監控告警規則。
5. 創建一個系統健康檢查儀表板。

## 小結 📝

- 學習了指標收集的方法
- 掌握了日誌管理技術
- 理解了分布式追踪原理
- 學會了監控系統實現
- 了解了可觀測性最佳實踐

## 延伸閱讀 📚

1. Observability Engineering
2. Prometheus Documentation
3. OpenTelemetry Guide
4. Elastic Stack Documentation
5. SRE Workbook

[上一章：大規模數據流處理](129_大規模數據流處理.md) 