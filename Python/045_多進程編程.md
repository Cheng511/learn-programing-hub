[上一章：多線程進階](044_多線程進階.md) | [下一章：GUI程式設計基礎](046_GUI程式設計基礎.md)

# Python 多進程編程 🚀

## 進程基礎

### 1. 創建進程

```python
import multiprocessing
import time
import os

def worker():
    """工作進程函數"""
    print(f"進程 {os.getpid()} 開始工作")
    time.sleep(2)
    print(f"進程 {os.getpid()} 完成工作")

if __name__ == '__main__':
    # 創建進程
    process = multiprocessing.Process(target=worker)
    process.start()
    process.join()

    # 創建多個進程
    processes = []
    for _ in range(3):
        p = multiprocessing.Process(target=worker)
        processes.append(p)
        p.start()

    # 等待所有進程完成
    for p in processes:
        p.join()
```

### 2. 進程類

```python
class WorkerProcess(multiprocessing.Process):
    def __init__(self, name):
        super().__init__()
        self.name = name
    
    def run(self):
        """進程執行的方法"""
        print(f"進程 {self.name} (PID: {os.getpid()}) 開始工作")
        time.sleep(2)
        print(f"進程 {self.name} (PID: {os.getpid()}) 完成工作")

if __name__ == '__main__':
    # 使用進程類
    worker = WorkerProcess("Worker-1")
    worker.start()
    worker.join()
```

## 進程間通信

### 1. 管道通信

```python
from multiprocessing import Pipe

def sender(conn):
    """發送數據的進程"""
    conn.send(['Hello', 42, {'key': 'value'}])
    conn.close()

def receiver(conn):
    """接收數據的進程"""
    data = conn.recv()
    print(f"接收到數據: {data}")
    conn.close()

if __name__ == '__main__':
    # 創建管道
    parent_conn, child_conn = Pipe()

    # 創建發送和接收進程
    p1 = multiprocessing.Process(target=sender, args=(parent_conn,))
    p2 = multiprocessing.Process(target=receiver, args=(child_conn,))

    p1.start()
    p2.start()

    p1.join()
    p2.join()
```

### 2. 隊列通信

```python
from multiprocessing import Queue
import random

class TaskQueue:
    def __init__(self):
        self.queue = Queue()
    
    def producer(self):
        """生產任務"""
        for i in range(5):
            task = f"Task-{i}"
            self.queue.put(task)
            print(f"生產任務: {task}")
            time.sleep(random.random())
    
    def consumer(self):
        """消費任務"""
        while True:
            try:
                task = self.queue.get(timeout=3)
                print(f"處理任務: {task}")
                time.sleep(random.random())
            except Queue.Empty:
                print("隊列為空，退出消費者")
                break

if __name__ == '__main__':
    # 使用任務隊列
    task_queue = TaskQueue()

    # 創建生產者和消費者進程
    producer = multiprocessing.Process(target=task_queue.producer)
    consumer = multiprocessing.Process(target=task_queue.consumer)

    producer.start()
    consumer.start()

    producer.join()
    consumer.join()
```

## 進程池

### 1. 基本進程池

```python
from multiprocessing import Pool
import random

def process_task(task_id):
    """處理任務"""
    print(f"開始處理任務 {task_id}")
    time.sleep(random.random() * 2)  # 模擬工作時間
    return f"Task {task_id} result"

if __name__ == '__main__':
    # 使用進程池
    with Pool(processes=4) as pool:
        # 提交多個任務
        results = pool.map(process_task, range(10))
        
        # 輸出結果
        for result in results:
            print(f"獲得結果: {result}")
```

### 2. 異步進程池

```python
from multiprocessing import Pool
from tqdm import tqdm

def async_process_task(tasks):
    """異步處理任務"""
    with Pool(processes=4) as pool:
        # 異步提交任務
        results = []
        with tqdm(total=len(tasks)) as pbar:
            for result in pool.imap_unordered(process_task, tasks):
                results.append(result)
                pbar.update(1)
        return results

if __name__ == '__main__':
    # 使用異步進程池
    tasks = range(10)
    results = async_process_task(tasks)
    print("所有任務完成！")
```

## 共享內存

### 1. 共享變量

```python
from multiprocessing import Value, Array

def increment_counter(counter):
    """增加共享計數器"""
    with counter.get_lock():
        counter.value += 1

def modify_array(shared_array, index, value):
    """修改共享數組"""
    shared_array[index] = value

if __name__ == '__main__':
    # 創建共享計數器
    counter = Value('i', 0)
    
    # 創建共享數組
    array = Array('i', range(5))
    
    # 創建多個進程操作共享變量
    processes = []
    for i in range(10):
        p = multiprocessing.Process(target=increment_counter, args=(counter,))
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()
    
    print(f"最終計數: {counter.value}")
    print(f"共享數組: {list(array)}")
```

### 2. 共享字典

```python
from multiprocessing import Manager

def update_dict(shared_dict, key, value):
    """更新共享字典"""
    shared_dict[key] = value

if __name__ == '__main__':
    # 創建管理器
    with Manager() as manager:
        # 創建共享字典
        shared_dict = manager.dict()
        
        # 創建多個進程更新字典
        processes = []
        for i in range(5):
            p = multiprocessing.Process(
                target=update_dict, 
                args=(shared_dict, f'key{i}', f'value{i}')
            )
            processes.append(p)
            p.start()
        
        for p in processes:
            p.join()
        
        print(f"共享字典: {dict(shared_dict)}")
```

## 實際應用範例

### 1. 並行圖像處理器

```python
from PIL import Image
import os
from multiprocessing import Pool

class ImageProcessor:
    def __init__(self, input_dir, output_dir):
        self.input_dir = input_dir
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)
    
    def process_image(self, filename):
        """處理單張圖片"""
        try:
            input_path = os.path.join(self.input_dir, filename)
            output_path = os.path.join(self.output_dir, filename)
            
            with Image.open(input_path) as img:
                # 調整圖片大小
                resized = img.resize((800, 600))
                # 增加亮度
                enhanced = resized.point(lambda p: p * 1.2)
                # 保存處理後的圖片
                enhanced.save(output_path)
            
            return f"成功處理: {filename}"
        except Exception as e:
            return f"處理失敗 {filename}: {str(e)}"
    
    def batch_process(self):
        """批量處理圖片"""
        filenames = [f for f in os.listdir(self.input_dir) 
                    if f.endswith(('.jpg', '.png'))]
        
        with Pool(processes=4) as pool:
            results = pool.map(self.process_image, filenames)
        
        return results

if __name__ == '__main__':
    # 使用圖像處理器
    processor = ImageProcessor('input_images', 'output_images')
    results = processor.batch_process()
    
    for result in results:
        print(result)
```

### 2. 數據分析系統

```python
import pandas as pd
import numpy as np
from multiprocessing import Pool

class DataAnalyzer:
    def __init__(self, data_file):
        self.data = pd.read_csv(data_file)
        self.chunks = np.array_split(self.data, 4)
    
    def analyze_chunk(self, chunk):
        """分析數據塊"""
        results = {
            'mean': chunk.mean(),
            'std': chunk.std(),
            'min': chunk.min(),
            'max': chunk.max()
        }
        return results
    
    def parallel_analyze(self):
        """並行分析數據"""
        with Pool(processes=4) as pool:
            chunk_results = pool.map(self.analyze_chunk, self.chunks)
        
        # 合併結果
        final_results = {}
        for key in ['mean', 'std', 'min', 'max']:
            values = [result[key] for result in chunk_results]
            final_results[key] = pd.concat(values)
        
        return final_results

if __name__ == '__main__':
    # 使用數據分析器
    analyzer = DataAnalyzer('large_dataset.csv')
    results = analyzer.parallel_analyze()
    
    print("分析結果:")
    for key, value in results.items():
        print(f"\n{key.upper()}:")
        print(value)
```

## 練習題

1. **並行文件處理器**
   實現一個並行文件處理系統：
   - 多進程讀取文件
   - 內容處理和轉換
   - 結果合併
   - 進度監控

2. **分布式計算系統**
   創建一個簡單的分布式計算系統：
   - 任務分配
   - 結果收集
   - 錯誤處理
   - 負載均衡

3. **數據處理管道**
   開發一個數據處理管道：
   - 數據預處理
   - 並行處理
   - 結果聚合
   - 性能優化

## 小提醒 💡

1. 合理使用進程數量
2. 注意內存使用
3. 處理進程間通信
4. 正確處理異常
5. 避免資源競爭
6. 及時清理資源

[上一章：多線程進階](044_多線程進階.md) | [下一章：GUI程式設計基礎](046_GUI程式設計基礎.md) 