[ä¸Šä¸€ç« ï¼šå¤šç·šç¨‹é€²éš](044_å¤šç·šç¨‹é€²éš.md) | [ä¸‹ä¸€ç« ï¼šGUIç¨‹å¼è¨­è¨ˆåŸºç¤](046_GUIç¨‹å¼è¨­è¨ˆåŸºç¤.md)

# Python å¤šé€²ç¨‹ç·¨ç¨‹ ğŸš€

## å¤šé€²ç¨‹åŸºç¤æ¦‚å¿µ

### 1. é€²ç¨‹èˆ‡ç·šç¨‹çš„å€åˆ¥

```python
"""
é€²ç¨‹ï¼ˆProcessï¼‰vs ç·šç¨‹ï¼ˆThreadï¼‰ä¸»è¦å€åˆ¥ï¼š

1. è³‡æºéš”é›¢ï¼š
   - é€²ç¨‹ï¼šå®Œå…¨ç¨ç«‹çš„è³‡æºç©ºé–“
   - ç·šç¨‹ï¼šå…±äº«æ‰€å±¬é€²ç¨‹çš„è³‡æº

2. é€šä¿¡æ–¹å¼ï¼š
   - é€²ç¨‹ï¼šéœ€è¦ç‰¹æ®Šçš„IPCæ©Ÿåˆ¶
   - ç·šç¨‹ï¼šå¯ç›´æ¥å…±äº«è®Šé‡

3. é–‹éŠ·ï¼š
   - é€²ç¨‹ï¼šå‰µå»ºå’Œåˆ‡æ›é–‹éŠ·å¤§
   - ç·šç¨‹ï¼šå‰µå»ºå’Œåˆ‡æ›é–‹éŠ·å°

4. ç©©å®šæ€§ï¼š
   - é€²ç¨‹ï¼šä¸€å€‹é€²ç¨‹å´©æ½°ä¸å½±éŸ¿å…¶ä»–é€²ç¨‹
   - ç·šç¨‹ï¼šä¸€å€‹ç·šç¨‹å´©æ½°å¯èƒ½å°è‡´æ•´å€‹é€²ç¨‹å´©æ½°
"""

import os
import multiprocessing
import threading

def show_info():
    print(f'é€²ç¨‹ID: {os.getpid()}')
    print(f'ç·šç¨‹ID: {threading.current_thread().ident}')
    print(f'çˆ¶é€²ç¨‹ID: {os.getppid()}')

if __name__ == '__main__':
    print("ä¸»é€²ç¨‹ä¿¡æ¯ï¼š")
    show_info()
    
    # å‰µå»ºå­é€²ç¨‹
    p = multiprocessing.Process(target=show_info)
    p.start()
    p.join()
```

### 2. å‰µå»ºé€²ç¨‹çš„æ–¹æ³•

```python
import multiprocessing
import time
import os

# æ–¹æ³•1ï¼šå‡½æ•¸æ–¹å¼
def worker_function():
    print(f'å·¥ä½œé€²ç¨‹ {os.getpid()} é–‹å§‹åŸ·è¡Œ')
    time.sleep(2)
    print(f'å·¥ä½œé€²ç¨‹ {os.getpid()} åŸ·è¡Œå®Œæˆ')

# æ–¹æ³•2ï¼šé¡æ–¹å¼
class WorkerProcess(multiprocessing.Process):
    def __init__(self, name):
        super().__init__()
        self.name = name
    
    def run(self):
        print(f'é€²ç¨‹ {self.name} ({os.getpid()}) é–‹å§‹åŸ·è¡Œ')
        time.sleep(2)
        print(f'é€²ç¨‹ {self.name} ({os.getpid()}) åŸ·è¡Œå®Œæˆ')

if __name__ == '__main__':
    # ä½¿ç”¨å‡½æ•¸å‰µå»ºé€²ç¨‹
    process1 = multiprocessing.Process(target=worker_function)
    process1.start()
    process1.join()
    
    # ä½¿ç”¨é¡å‰µå»ºé€²ç¨‹
    process2 = WorkerProcess("Worker-1")
    process2.start()
    process2.join()
    
    # å‰µå»ºå¤šå€‹é€²ç¨‹
    processes = []
    for i in range(3):
        p = WorkerProcess(f"Worker-{i}")
        processes.append(p)
        p.start()
    
    for p in processes:
        p.join()
```

## é€²ç¨‹é–“é€šä¿¡ï¼ˆIPCï¼‰

### 1. ç®¡é“ï¼ˆPipeï¼‰é€šä¿¡

```python
from multiprocessing import Pipe, Process
import time

def sender(conn, messages):
    """ç™¼é€æ•¸æ“šçš„é€²ç¨‹"""
    for msg in messages:
        conn.send(msg)
        print(f"ç™¼é€: {msg}")
        time.sleep(1)
    conn.close()

def receiver(conn):
    """æ¥æ”¶æ•¸æ“šçš„é€²ç¨‹"""
    while True:
        try:
            msg = conn.recv()
            print(f"æ¥æ”¶: {msg}")
        except EOFError:
            break
    conn.close()

if __name__ == '__main__':
    # å‰µå»ºç®¡é“
    parent_conn, child_conn = Pipe()
    
    # æº–å‚™ç™¼é€çš„æ¶ˆæ¯
    messages = ['Hello', 42, {'key': 'value'}, [1, 2, 3]]
    
    # å‰µå»ºç™¼é€å’Œæ¥æ”¶é€²ç¨‹
    p1 = Process(target=sender, args=(parent_conn, messages))
    p2 = Process(target=receiver, args=(child_conn,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
```

### 2. éšŠåˆ—ï¼ˆQueueï¼‰é€šä¿¡

```python
from multiprocessing import Queue, Process
import time
import random

class TaskManager:
    def __init__(self):
        self.task_queue = Queue()
        self.result_queue = Queue()
    
    def producer(self, num_tasks):
        """ç”Ÿç”¢ä»»å‹™"""
        for i in range(num_tasks):
            task = f"Task-{i}"
            self.task_queue.put(task)
            print(f"ç”Ÿç”¢ä»»å‹™: {task}")
            time.sleep(random.random())
        
        # æ·»åŠ çµæŸæ¨™è¨˜
        self.task_queue.put(None)
    
    def consumer(self):
        """æ¶ˆè²»ä»»å‹™"""
        while True:
            task = self.task_queue.get()
            if task is None:
                break
            
            # è™•ç†ä»»å‹™
            result = f"Result of {task}"
            print(f"è™•ç†ä»»å‹™: {task}")
            self.result_queue.put(result)
            time.sleep(random.random())
    
    def result_collector(self, expected_results):
        """æ”¶é›†çµæœ"""
        results = []
        while len(results) < expected_results:
            result = self.result_queue.get()
            results.append(result)
            print(f"æ”¶é›†çµæœ: {result}")
        return results

if __name__ == '__main__':
    manager = TaskManager()
    num_tasks = 5
    
    # å‰µå»ºç”Ÿç”¢è€…ã€æ¶ˆè²»è€…å’Œçµæœæ”¶é›†é€²ç¨‹
    producer = Process(target=manager.producer, args=(num_tasks,))
    consumer = Process(target=manager.consumer)
    collector = Process(target=manager.result_collector, args=(num_tasks,))
    
    producer.start()
    consumer.start()
    collector.start()
    
    producer.join()
    consumer.join()
    collector.join()
```

## é€²ç¨‹æ± 

### 1. åŸºæœ¬é€²ç¨‹æ± 

```python
from multiprocessing import Pool
import time
import random

def process_task(task_id):
    """è™•ç†å–®å€‹ä»»å‹™"""
    print(f"é–‹å§‹è™•ç†ä»»å‹™ {task_id}")
    processing_time = random.uniform(0.5, 2)
    time.sleep(processing_time)
    return f"ä»»å‹™ {task_id} å®Œæˆï¼Œè™•ç†æ™‚é–“: {processing_time:.2f}ç§’"

class TaskProcessor:
    def __init__(self, num_processes):
        self.pool = Pool(processes=num_processes)
    
    def process_tasks(self, num_tasks):
        """æ‰¹é‡è™•ç†ä»»å‹™"""
        tasks = range(num_tasks)
        
        # ä½¿ç”¨mapæ–¹æ³•
        results = self.pool.map(process_task, tasks)
        
        # é—œé–‰é€²ç¨‹æ± 
        self.pool.close()
        self.pool.join()
        
        return results

if __name__ == '__main__':
    processor = TaskProcessor(4)
    results = processor.process_tasks(10)
    
    print("\nè™•ç†çµæœ:")
    for result in results:
        print(result)
```

### 2. ç•°æ­¥é€²ç¨‹æ± 

```python
from multiprocessing import Pool
import time
import random
from tqdm import tqdm

def async_task(task_id):
    """ç•°æ­¥ä»»å‹™è™•ç†"""
    time.sleep(random.uniform(0.5, 2))
    return f"ä»»å‹™ {task_id} å®Œæˆ"

class AsyncTaskProcessor:
    def __init__(self, num_processes):
        self.pool = Pool(processes=num_processes)
    
    def process_tasks_async(self, num_tasks):
        """ç•°æ­¥è™•ç†ä»»å‹™"""
        # æäº¤æ‰€æœ‰ä»»å‹™
        futures = []
        for i in range(num_tasks):
            future = self.pool.apply_async(async_task, (i,))
            futures.append(future)
        
        # ä½¿ç”¨é€²åº¦æ¢æ”¶é›†çµæœ
        results = []
        with tqdm(total=num_tasks) as pbar:
            for future in futures:
                result = future.get()
                results.append(result)
                pbar.update(1)
        
        # é—œé–‰é€²ç¨‹æ± 
        self.pool.close()
        self.pool.join()
        
        return results

if __name__ == '__main__':
    processor = AsyncTaskProcessor(4)
    results = processor.process_tasks_async(10)
    
    print("\nè™•ç†çµæœ:")
    for result in results:
        print(result)
```

## å…±äº«å…§å­˜å’ŒåŒæ­¥

### 1. å…±äº«å…§å­˜

```python
from multiprocessing import Process, Value, Array
import time

def increment_counter(counter, array):
    """å¢åŠ å…±äº«è¨ˆæ•¸å™¨ä¸¦ä¿®æ”¹å…±äº«æ•¸çµ„"""
    with counter.get_lock():
        counter.value += 1
        print(f"è¨ˆæ•¸å™¨å¢åŠ åˆ°: {counter.value}")
    
    # ä¿®æ”¹å…±äº«æ•¸çµ„
    for i in range(len(array)):
        array[i] *= 2
        time.sleep(0.1)

if __name__ == '__main__':
    # å‰µå»ºå…±äº«è¨ˆæ•¸å™¨å’Œæ•¸çµ„
    counter = Value('i', 0)
    array = Array('i', range(5))
    
    # å‰µå»ºå¤šå€‹é€²ç¨‹
    processes = []
    for _ in range(3):
        p = Process(target=increment_counter, args=(counter, array))
        processes.append(p)
        p.start()
    
    # ç­‰å¾…æ‰€æœ‰é€²ç¨‹å®Œæˆ
    for p in processes:
        p.join()
    
    print(f"æœ€çµ‚è¨ˆæ•¸å™¨å€¼: {counter.value}")
    print(f"æœ€çµ‚æ•¸çµ„å€¼: {list(array)}")
```

### 2. é€²ç¨‹é–å’Œä¿¡è™Ÿé‡

```python
from multiprocessing import Process, Lock, Semaphore
import time
import random

class ResourceManager:
    def __init__(self, num_resources):
        self.lock = Lock()
        self.semaphore = Semaphore(num_resources)
        self.resources = list(range(num_resources))
    
    def acquire_resource(self, process_id):
        """ç²å–è³‡æº"""
        self.semaphore.acquire()
        with self.lock:
            resource = self.resources.pop()
            print(f"é€²ç¨‹ {process_id} ç²å–è³‡æº {resource}")
            return resource
    
    def release_resource(self, process_id, resource):
        """é‡‹æ”¾è³‡æº"""
        with self.lock:
            self.resources.append(resource)
            print(f"é€²ç¨‹ {process_id} é‡‹æ”¾è³‡æº {resource}")
        self.semaphore.release()

def worker(manager, process_id):
    """å·¥ä½œé€²ç¨‹"""
    try:
        # ç²å–è³‡æº
        resource = manager.acquire_resource(process_id)
        
        # ä½¿ç”¨è³‡æº
        time.sleep(random.uniform(0.5, 2))
        
        # é‡‹æ”¾è³‡æº
        manager.release_resource(process_id, resource)
    except Exception as e:
        print(f"é€²ç¨‹ {process_id} ç™¼ç”ŸéŒ¯èª¤: {e}")

if __name__ == '__main__':
    # å‰µå»ºè³‡æºç®¡ç†å™¨
    manager = ResourceManager(3)
    
    # å‰µå»ºå¤šå€‹å·¥ä½œé€²ç¨‹
    processes = []
    for i in range(5):
        p = Process(target=worker, args=(manager, i))
        processes.append(p)
        p.start()
    
    # ç­‰å¾…æ‰€æœ‰é€²ç¨‹å®Œæˆ
    for p in processes:
        p.join()
```

## å¯¦éš›æ‡‰ç”¨ç¯„ä¾‹

### 1. ä¸¦è¡Œåœ–åƒè™•ç†å™¨

```python
from multiprocessing import Pool
from PIL import Image
import os
import time

class ImageProcessor:
    def __init__(self, input_dir, output_dir, num_processes=4):
        self.input_dir = input_dir
        self.output_dir = output_dir
        self.num_processes = num_processes
        
        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        os.makedirs(output_dir, exist_ok=True)
    
    def process_image(self, filename):
        """è™•ç†å–®å¼µåœ–ç‰‡"""
        try:
            # æ§‹å»ºå®Œæ•´è·¯å¾‘
            input_path = os.path.join(self.input_dir, filename)
            output_path = os.path.join(self.output_dir, f"processed_{filename}")
            
            # æ‰“é–‹ä¸¦è™•ç†åœ–ç‰‡
            with Image.open(input_path) as img:
                # èª¿æ•´å¤§å°
                resized = img.resize((800, 600))
                
                # å¢åŠ äº®åº¦
                enhanced = resized.point(lambda p: p * 1.2)
                
                # æ·»åŠ æ°´å°
                if enhanced.mode != 'RGBA':
                    enhanced = enhanced.convert('RGBA')
                
                # ä¿å­˜è™•ç†å¾Œçš„åœ–ç‰‡
                enhanced.save(output_path, 'PNG')
            
            return f"æˆåŠŸè™•ç†: {filename}"
        except Exception as e:
            return f"è™•ç†å¤±æ•— {filename}: {str(e)}"
    
    def batch_process(self):
        """æ‰¹é‡è™•ç†åœ–ç‰‡"""
        # ç²å–æ‰€æœ‰åœ–ç‰‡æ–‡ä»¶
        image_files = [f for f in os.listdir(self.input_dir) 
                      if f.lower().endswith(('.png', '.jpg', '.jpeg'))]
        
        # ä½¿ç”¨é€²ç¨‹æ± è™•ç†åœ–ç‰‡
        start_time = time.time()
        with Pool(processes=self.num_processes) as pool:
            results = pool.map(self.process_image, image_files)
        
        # è¨ˆç®—è™•ç†æ™‚é–“
        processing_time = time.time() - start_time
        
        # çµ±è¨ˆçµæœ
        success = sum(1 for r in results if r.startswith('æˆåŠŸ'))
        failed = len(results) - success
        
        return {
            'total': len(results),
            'success': success,
            'failed': failed,
            'processing_time': processing_time,
            'results': results
        }

if __name__ == '__main__':
    # ä½¿ç”¨åœ–åƒè™•ç†å™¨
    processor = ImageProcessor('input_images', 'output_images')
    results = processor.batch_process()
    
    # è¼¸å‡ºè™•ç†çµæœ
    print(f"\nè™•ç†å®Œæˆï¼")
    print(f"ç¸½æ•¸: {results['total']}")
    print(f"æˆåŠŸ: {results['success']}")
    print(f"å¤±æ•—: {results['failed']}")
    print(f"è™•ç†æ™‚é–“: {results['processing_time']:.2f} ç§’")
    
    print("\nè©³ç´°çµæœ:")
    for result in results['results']:
        print(result)
```

### 2. ä¸¦è¡Œæ•¸æ“šåˆ†æç³»çµ±

```python
import pandas as pd
import numpy as np
from multiprocessing import Pool, Manager
import time

class DataAnalyzer:
    def __init__(self, num_processes=4):
        self.num_processes = num_processes
    
    def analyze_chunk(self, chunk_data):
        """åˆ†ææ•¸æ“šå¡Š"""
        try:
            results = {
                'count': len(chunk_data),
                'mean': chunk_data.mean(),
                'std': chunk_data.std(),
                'min': chunk_data.min(),
                'max': chunk_data.max(),
                'median': chunk_data.median()
            }
            return results
        except Exception as e:
            return f"åˆ†æå¤±æ•—: {str(e)}"
    
    def parallel_analyze(self, data_file):
        """ä¸¦è¡Œåˆ†ææ•¸æ“š"""
        try:
            # è®€å–æ•¸æ“š
            start_time = time.time()
            df = pd.read_csv(data_file)
            
            # å°‡æ•¸æ“šåˆ†å‰²æˆå¤šå€‹å¡Š
            chunks = np.array_split(df, self.num_processes)
            
            # ä½¿ç”¨é€²ç¨‹æ± é€²è¡Œåˆ†æ
            with Pool(processes=self.num_processes) as pool:
                chunk_results = pool.map(self.analyze_chunk, chunks)
            
            # åˆä½µçµæœ
            final_results = {
                'total_records': sum(r['count'] for r in chunk_results),
                'mean': np.mean([r['mean'] for r in chunk_results]),
                'std': np.mean([r['std'] for r in chunk_results]),
                'min': min(r['min'] for r in chunk_results),
                'max': max(r['max'] for r in chunk_results),
                'median': np.median([r['median'] for r in chunk_results]),
                'processing_time': time.time() - start_time
            }
            
            return final_results
        except Exception as e:
            return f"åˆ†æå¤±æ•—: {str(e)}"

if __name__ == '__main__':
    # ä½¿ç”¨æ•¸æ“šåˆ†æå™¨
    analyzer = DataAnalyzer()
    results = analyzer.parallel_analyze('large_dataset.csv')
    
    # è¼¸å‡ºåˆ†æçµæœ
    print("\næ•¸æ“šåˆ†æçµæœ:")
    print(f"ç¸½è¨˜éŒ„æ•¸: {results['total_records']}")
    print(f"å¹³å‡å€¼: {results['mean']:.2f}")
    print(f"æ¨™æº–å·®: {results['std']:.2f}")
    print(f"æœ€å°å€¼: {results['min']:.2f}")
    print(f"æœ€å¤§å€¼: {results['max']:.2f}")
    print(f"ä¸­ä½æ•¸: {results['median']:.2f}")
    print(f"è™•ç†æ™‚é–“: {results['processing_time']:.2f} ç§’")
```

## ç·´ç¿’é¡Œ

1. **ä¸¦è¡Œæ–‡ä»¶æœç´¢å™¨**
   å¯¦ç¾ä¸€å€‹ä¸¦è¡Œæ–‡ä»¶æœç´¢ç³»çµ±ï¼š
   - å¤šé€²ç¨‹æœç´¢æ–‡ä»¶
   - æ”¯æŒæ­£å‰‡è¡¨é”å¼åŒ¹é…
   - å³æ™‚é¡¯ç¤ºæœç´¢çµæœ
   - å¯ä¸­æ–·çš„æœç´¢éç¨‹

2. **åˆ†å¸ƒå¼è¨ˆç®—æ¡†æ¶**
   å‰µå»ºä¸€å€‹ç°¡å–®çš„åˆ†å¸ƒå¼è¨ˆç®—æ¡†æ¶ï¼š
   - ä»»å‹™åˆ†é…å™¨
   - å·¥ä½œé€²ç¨‹æ± 
   - çµæœæ”¶é›†å™¨
   - éŒ¯èª¤è™•ç†æ©Ÿåˆ¶

3. **é«˜æ€§èƒ½æ•¸æ“šè™•ç†ç®¡é“**
   é–‹ç™¼ä¸€å€‹æ•¸æ“šè™•ç†ç®¡é“ï¼š
   - æ•¸æ“šé è™•ç†
   - ä¸¦è¡Œç‰¹å¾µæå–
   - çµæœèšåˆ
   - æ€§èƒ½ç›£æ§

## å°æé†’ ğŸ’¡

1. åˆç†ä½¿ç”¨é€²ç¨‹æ•¸é‡
   - è€ƒæ…®CPUæ ¸å¿ƒæ•¸
   - æ³¨æ„å…§å­˜ä½¿ç”¨æƒ…æ³
   - é¿å…éåº¦å‰µå»ºé€²ç¨‹

2. æ­£ç¢ºè™•ç†é€²ç¨‹é–“é€šä¿¡
   - é¸æ“‡åˆé©çš„é€šä¿¡æ–¹å¼
   - è™•ç†é€šä¿¡ç•°å¸¸
   - é¿å…æ­»é–æƒ…æ³

3. è³‡æºç®¡ç†
   - åŠæ™‚é‡‹æ”¾è³‡æº
   - æ­£ç¢ºé—œé–‰é€²ç¨‹
   - è™•ç†ç•°å¸¸æƒ…æ³

4. æ€§èƒ½å„ªåŒ–
   - æ¸›å°‘é€²ç¨‹é–“é€šä¿¡
   - åˆç†åˆ†é…ä»»å‹™
   - ç›£æ§ç³»çµ±è³‡æº

5. èª¿è©¦æŠ€å·§
   - ä½¿ç”¨æ—¥èªŒè¨˜éŒ„
   - æ·»åŠ èª¿è©¦ä¿¡æ¯
   - é€²è¡Œæ€§èƒ½åˆ†æ

6. å®‰å…¨è€ƒæ…®
   - è™•ç†æ•æ„Ÿæ•¸æ“š
   - é˜²æ­¢è³‡æºæ´©éœ²
   - è€ƒæ…®ä¸¦ç™¼å®‰å…¨

[ä¸Šä¸€ç« ï¼šå¤šç·šç¨‹é€²éš](044_å¤šç·šç¨‹é€²éš.md) | [ä¸‹ä¸€ç« ï¼šGUIç¨‹å¼è¨­è¨ˆåŸºç¤](046_GUIç¨‹å¼è¨­è¨ˆåŸºç¤.md) 